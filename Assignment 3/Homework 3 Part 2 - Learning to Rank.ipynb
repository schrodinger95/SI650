{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Oe730o8rzyn"
   },
   "source": [
    "# SI 650 / EECS 549: Homework 3 Part 2\n",
    "\n",
    "Homework 3 Part 2 will have you working with Learning to Rank approaches, which as we've seen are highly competitive when enough data is available. Part 2 should be completed after Part 1 and will use some small parts of that code to construct an index and load data.\n",
    "\n",
    "If you haven't worked with them before, Part 2 will expose you to [overloaded python operators](https://www.geeksforgeeks.org/operator-overloading-in-python/), which will let you call functions using alternative python syntax. For example, if you're using two Python `list` objects, you can interact with them using `+` to call the equivalent method. \n",
    "\n",
    "In Part 2, you'll work on the following tasks:\n",
    " - Construct and learn learning-to-rank pipelines\n",
    " - Add new features for learning-to-rank\n",
    " - Evaluate learning-to-rank models\n",
    " \n",
    "Part 2 can be run on most laptops as well. Some of the machine learning models may take a few minutes to train but you are also welcome to run these on Great Lakes. None of the code in this part involves deep learning or requires a GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0edvI3LDtOym"
   },
   "source": [
    "### Launch PyTerrier\n",
    "Import the packages you need and launch PyTerrier like we did in Part 1. You will still need to make sure `JAVA_HOME` is set for this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34696,
     "status": "ok",
     "timestamp": 1616668024544,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "mkCdrWdRzS64",
    "outputId": "c6770726-25a2-4971-b1e6-6fb44efb4f83"
   },
   "outputs": [],
   "source": [
    "import pyterrier as pt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37396,
     "status": "ok",
     "timestamp": 1616668027562,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "SWc4UQgX6vDD",
    "outputId": "30cd0f3d-aafe-428f-eaa4-9163de61d4af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.7.1 has loaded Terrier 5.6 (built by craigmacdonald on 2021-09-17 13:27)\n"
     ]
    }
   ],
   "source": [
    "if not pt.started():\n",
    "    pt.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p18d1tpJvD_5"
   },
   "source": [
    "# Indexing CORD19\n",
    "\n",
    "Like in Part 1, we'll again use the CORD19 data. However, **in Part 2, we will add in positional indexing.** This code will still look very similar to your code from Part 1. When creating the index, add the `blocks=True` argument, which will include word order information in the index. On most laptops, this process will take ~1 minute.\n",
    "\n",
    "You may see an error `java.io.IOException: Key 8lqzfj2e is not unique: 37597,11755` during indexing but you can safely ignore the error for the purposes of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 239,
     "referenced_widgets": [
      "562458b5bd6d4bb3a629932a2edc54d7",
      "224e088c2ac64cc29b1d78a5e850ebe4",
      "3cc8a8231dc44c768dffbc755dd0f2fb",
      "d998ea1d78fa458d94e3107bc2a514b5",
      "ae5b4e71f7a74bb8aaa7c8bf1e985993",
      "587cc3f3700b4201b750e8fd3408e34d",
      "c6b946af922e4b248a5bfecd99e11a8c",
      "eb34c2ee16c241ea955bb088632f603d"
     ]
    },
    "executionInfo": {
     "elapsed": 135816,
     "status": "ok",
     "timestamp": 1616668163381,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "C9E6oLubIeI4",
    "outputId": "0170a2d2-169e-4377-c538-a335efd8dec8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cord19/trec-covid documents:   0%|          | 14/192509 [00:01<9:09:41,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:29:00.595 [ForkJoinPool-1-worker-3] WARN org.terrier.structures.indexing.Indexer - Adding an empty document to the index (6iu1dtyl) - further warnings are suppressed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cord19/trec-covid documents: 100%|██████████| 192509/192509 [01:03<00:00, 3036.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:30:02.927 [ForkJoinPool-1-worker-3] WARN org.terrier.structures.indexing.Indexer - Indexed 54937 empty documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:30:03.850 [ForkJoinPool-1-worker-3] ERROR org.terrier.structures.indexing.Indexer - Could not finish MetaIndexBuilder: \n",
      "java.io.IOException: Key 8lqzfj2e is not unique: 37597,11755\n",
      "For MetaIndex, to suppress, set metaindex.compressed.reverse.allow.duplicates=true\n",
      "\tat org.terrier.structures.collections.FSOrderedMapFile$MultiFSOMapWriter.mergeTwo(FSOrderedMapFile.java:1374)\n",
      "\tat org.terrier.structures.collections.FSOrderedMapFile$MultiFSOMapWriter.close(FSOrderedMapFile.java:1308)\n",
      "\tat org.terrier.structures.indexing.BaseMetaIndexBuilder.close(BaseMetaIndexBuilder.java:321)\n",
      "\tat org.terrier.structures.indexing.classical.BlockIndexer.createDirectIndex(BlockIndexer.java:472)\n",
      "\tat org.terrier.structures.indexing.Indexer.index(Indexer.java:369)\n",
      "\tat org.terrier.python.ParallelIndexer$1.apply(ParallelIndexer.java:63)\n",
      "\tat org.terrier.python.ParallelIndexer$1.apply(ParallelIndexer.java:52)\n",
      "\tat java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)\n",
      "\tat java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)\n",
      "\tat java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)\n",
      "\tat java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)\n",
      "\tat java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(ReduceOps.java:952)\n",
      "\tat java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(ReduceOps.java:926)\n",
      "\tat java.base/java.util.stream.AbstractTask.compute(AbstractTask.java:327)\n",
      "\tat java.base/java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:746)\n",
      "\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)\n",
      "\tat java.base/java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:408)\n",
      "\tat java.base/java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:736)\n",
      "\tat java.base/java.util.stream.ReduceOps$ReduceOp.evaluateParallel(ReduceOps.java:919)\n",
      "\tat java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)\n",
      "\tat java.base/java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:558)\n",
      "\tat org.terrier.python.ParallelIndexer$3.call(ParallelIndexer.java:133)\n",
      "\tat org.terrier.python.ParallelIndexer$3.call(ParallelIndexer.java:130)\n",
      "\tat java.base/java.util.concurrent.ForkJoinTask$AdaptedCallable.exec(ForkJoinTask.java:1448)\n",
      "\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)\n",
      "\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)\n",
      "\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)\n",
      "\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)\n",
      "\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)\n"
     ]
    }
   ],
   "source": [
    "cord19 = pt.datasets.get_dataset('irds:cord19/trec-covid')\n",
    "pt_index_path = './terrier_trec_covid_positional_indices'\n",
    "\n",
    "if not os.path.exists(pt_index_path + \"/data.properties\"):\n",
    "    # create the index, using the IterDictIndexer indexer \n",
    "    indexer = pt.IterDictIndexer(pt_index_path, blocks=True)\n",
    "\n",
    "    # we give the dataset get_corpus_iter() directly to the indexer\n",
    "    # while specifying the fields to index and the metadata to record\n",
    "    index_ref = indexer.index(cord19.get_corpus_iter(), fields=('abstract',), meta=('docno',))\n",
    "\n",
    "else:\n",
    "    # if you already have the index, use it.\n",
    "    index_ref = pt.IndexRef.of(pt_index_path + \"/data.properties\")\n",
    "\n",
    "index = pt.IndexFactory.of(index_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OiM8I_fkUcQ9"
   },
   "source": [
    "## Transformers and Operators\n",
    "\n",
    "PyTerrier works extensively with objects/functions that _transform_ one input to another. We saw this behavior with the `BatchRetrieve` object that we used earlier to get search results, which had a `transform()` method that takes as input a dataframe, and returns another dataframe. We can think of this function as a *transformation* of the earlier dataframe (e.g., transforming the queries into results). PyTerrier has many such functions that act as  [transformers](https://pyterrier.readthedocs.io/en/latest/transformer.html). \n",
    "\n",
    "Let's use the transformer, `BatchRetrieve`, and this time specify that we'll use the TF-IDF word model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 554,
     "status": "ok",
     "timestamp": 1616668164873,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "UqMt-9UlTqLa",
    "outputId": "96e17d34-c984-418d-b087-24302b758e15"
   },
   "outputs": [],
   "source": [
    "tfidf = pt.BatchRetrieve(index, wmodel=\"TF_IDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GW3afDgPukvU"
   },
   "source": [
    "In PyTerrier, all transformers have been coded so that they be combined using Python operators, which is an example  of operator overloading. If we want to have the output of one transformer used as the input of another transformer, we can use the `>>` operator. This operator lets us compose a series of transformations to output our document rankings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "executionInfo": {
     "elapsed": 1823,
     "status": "ok",
     "timestamp": 1616668219672,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "e9HkXxtgug15",
    "outputId": "6bdd961d-4ff2-4b17-ffb6-6bbc6a42670a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuruge/opt/anaconda3/lib/python3.8/site-packages/pyterrier/datasets.py:430: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df.drop(df.columns.difference(['qid','query']), 1, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>146967</td>\n",
       "      <td>jkrj0lbm</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25564</td>\n",
       "      <td>jlzncyax</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>45549</td>\n",
       "      <td>8l411r1w</td>\n",
       "      <td>2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>29359</td>\n",
       "      <td>gnxbfcod</td>\n",
       "      <td>3</td>\n",
       "      <td>14.0</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>63537</td>\n",
       "      <td>cpc6v40g</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1</td>\n",
       "      <td>58583</td>\n",
       "      <td>wfcyaumm</td>\n",
       "      <td>995</td>\n",
       "      <td>4.0</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1</td>\n",
       "      <td>59153</td>\n",
       "      <td>86vu0kjm</td>\n",
       "      <td>996</td>\n",
       "      <td>4.0</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1</td>\n",
       "      <td>59343</td>\n",
       "      <td>9n733bet</td>\n",
       "      <td>997</td>\n",
       "      <td>4.0</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1</td>\n",
       "      <td>59478</td>\n",
       "      <td>mx58ai55</td>\n",
       "      <td>998</td>\n",
       "      <td>4.0</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1</td>\n",
       "      <td>59875</td>\n",
       "      <td>d0x23frk</td>\n",
       "      <td>999</td>\n",
       "      <td>4.0</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    qid   docid     docno  rank  score               query\n",
       "0     1  146967  jkrj0lbm     0   25.0  coronavirus origin\n",
       "1     1   25564  jlzncyax     1   18.0  coronavirus origin\n",
       "2     1   45549  8l411r1w     2   15.0  coronavirus origin\n",
       "3     1   29359  gnxbfcod     3   14.0  coronavirus origin\n",
       "4     1   63537  cpc6v40g     4   14.0  coronavirus origin\n",
       "..   ..     ...       ...   ...    ...                 ...\n",
       "995   1   58583  wfcyaumm   995    4.0  coronavirus origin\n",
       "996   1   59153  86vu0kjm   996    4.0  coronavirus origin\n",
       "997   1   59343  9n733bet   997    4.0  coronavirus origin\n",
       "998   1   59478  mx58ai55   998    4.0  coronavirus origin\n",
       "999   1   59875  d0x23frk   999    4.0  coronavirus origin\n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is our first retrieval transformer, which transforms a queries dataframe to a results dataframe\n",
    "tf = pt.BatchRetrieve(index, wmodel=\"Tf\")\n",
    "\n",
    "tf( cord19.get_topics(variant='title').head(1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define our first pipeline using the `>>` operator. If we have two transformers, `a` and `b`, the result of `a >> b` is itself a transformer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "executionInfo": {
     "elapsed": 878,
     "status": "ok",
     "timestamp": 1616668229117,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "uHHIn-rMvk_5",
    "outputId": "2060c226-bbea-46db-e0a8-57f0086fc3d6"
   },
   "outputs": [],
   "source": [
    "pipeline = tf >> tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this pipeline like any other transformer. Here, we'll  pass in the very first query using `head(1)` and get the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuruge/opt/anaconda3/lib/python3.8/site-packages/pyterrier/datasets.py:430: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df.drop(df.columns.difference(['qid','query']), 1, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>175892</td>\n",
       "      <td>zy8qjaai</td>\n",
       "      <td>0</td>\n",
       "      <td>7.080599</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>82224</td>\n",
       "      <td>8ccl9aui</td>\n",
       "      <td>1</td>\n",
       "      <td>6.775667</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>135326</td>\n",
       "      <td>ne5r4d4b</td>\n",
       "      <td>2</td>\n",
       "      <td>6.683114</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>93245</td>\n",
       "      <td>hmvo5b0q</td>\n",
       "      <td>3</td>\n",
       "      <td>6.507303</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>84953</td>\n",
       "      <td>ax6v6ham</td>\n",
       "      <td>4</td>\n",
       "      <td>6.483723</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1</td>\n",
       "      <td>136214</td>\n",
       "      <td>ygnxmcl1</td>\n",
       "      <td>995</td>\n",
       "      <td>1.640752</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1</td>\n",
       "      <td>91270</td>\n",
       "      <td>853ipgea</td>\n",
       "      <td>996</td>\n",
       "      <td>1.634118</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1</td>\n",
       "      <td>146556</td>\n",
       "      <td>oshov14d</td>\n",
       "      <td>997</td>\n",
       "      <td>1.634118</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1</td>\n",
       "      <td>32462</td>\n",
       "      <td>xtfjw1ag</td>\n",
       "      <td>998</td>\n",
       "      <td>1.592462</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1</td>\n",
       "      <td>145307</td>\n",
       "      <td>vr7vm64u</td>\n",
       "      <td>999</td>\n",
       "      <td>1.472311</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    qid   docid     docno  rank     score               query\n",
       "0     1  175892  zy8qjaai     0  7.080599  coronavirus origin\n",
       "1     1   82224  8ccl9aui     1  6.775667  coronavirus origin\n",
       "2     1  135326  ne5r4d4b     2  6.683114  coronavirus origin\n",
       "3     1   93245  hmvo5b0q     3  6.507303  coronavirus origin\n",
       "4     1   84953  ax6v6ham     4  6.483723  coronavirus origin\n",
       "..   ..     ...       ...   ...       ...                 ...\n",
       "995   1  136214  ygnxmcl1   995  1.640752  coronavirus origin\n",
       "996   1   91270  853ipgea   996  1.634118  coronavirus origin\n",
       "997   1  146556  oshov14d   997  1.634118  coronavirus origin\n",
       "998   1   32462  xtfjw1ag   998  1.592462  coronavirus origin\n",
       "999   1  145307  vr7vm64u   999  1.472311  coronavirus origin\n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline(cord19.get_topics(variant='title').head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r1yCXIB5w1Qb"
   },
   "source": [
    "There many other PyTerrier operators and please see examples in the [PyTerrier documentation on operators](https://pyterrier.readthedocs.io/en/latest/operators.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NaYavGvnxDk5"
   },
   "source": [
    "## Task 1: Pipeline Construction (15 ponts)\n",
    "\n",
    "Create a ranker that performs the following:\n",
    " - obtains the top 10 highest scoring documents by term frequency (`wmodel=\"Tf\"`)\n",
    " - obtains the top 10 highest scoring documents by TF.IDF (`wmodel=\"TF_IDF\"`)\n",
    " - reranks only those documents found in BOTH of the previous retrieval settings using BM25.\n",
    "\n",
    "How many documents are retrieved by this full pipeline for the query `\"chemical\"`.\n",
    "> If you obtain the correct solution, the document with docno `\"37771\"` should have a score of $12.426309\t$ for query `\"chemical\"`.\n",
    "\n",
    "Hints:\n",
    " - choose carefully your [PyTerrier operators](https://pyterrier.readthedocs.io/en/latest/operators.html)\n",
    " - you should not need to perform any Pandas dataframe operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 634,
     "status": "ok",
     "timestamp": 1616668361281,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "XnsRdT4WvspD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuruge/opt/anaconda3/lib/python3.8/site-packages/pyterrier/transformer.py:544: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  res = self.transformer.transform(topics_and_res)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>37771</td>\n",
       "      <td>jn5qi1jb</td>\n",
       "      <td>0</td>\n",
       "      <td>12.426309</td>\n",
       "      <td>chemical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>134305</td>\n",
       "      <td>0smev8vt</td>\n",
       "      <td>1</td>\n",
       "      <td>12.292890</td>\n",
       "      <td>chemical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>142104</td>\n",
       "      <td>77c9ohxj</td>\n",
       "      <td>2</td>\n",
       "      <td>12.226076</td>\n",
       "      <td>chemical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>56631</td>\n",
       "      <td>sps45fj5</td>\n",
       "      <td>3</td>\n",
       "      <td>11.642770</td>\n",
       "      <td>chemical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2524</td>\n",
       "      <td>ifebw24e</td>\n",
       "      <td>4</td>\n",
       "      <td>11.439890</td>\n",
       "      <td>chemical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid   docid     docno  rank      score     query\n",
       "0   1   37771  jn5qi1jb     0  12.426309  chemical\n",
       "1   1  134305  0smev8vt     1  12.292890  chemical\n",
       "2   1  142104  77c9ohxj     2  12.226076  chemical\n",
       "3   1   56631  sps45fj5     3  11.642770  chemical\n",
       "4   1    2524  ifebw24e     4  11.439890  chemical"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = pt.BatchRetrieve(index, wmodel=\"Tf\")\n",
    "tf_idf = pt.BatchRetrieve(index, wmodel=\"TF_IDF\")\n",
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
    "pipeline = ((tf % 10) & (tf_idf % 10)) >> bm25\n",
    "pipeline(\"chemical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4g8V7Zzpy3g1"
   },
   "source": [
    "## Developing more complex transformers pipelines\n",
    "\n",
    "PyTerrier has a number of useful transformers that we can use to create complex retrieval pipelines. For composing pipelines, let's first define a bit of notation:\n",
    " - $Q$: a set of queries\n",
    " - $D$: a set of documents\n",
    " - $R$: a set of retrieved documents for a set of queries\n",
    "\n",
    "In our setting, we'll use three transformers:\n",
    " - `pt.BatchRetrieve(index, wmodel=\"BM25\")` - input $Q$ or $R$ (retrieval or reranking), output $R$\n",
    " - `pt.rewrite.SDM()` (sequential dependence proximity model) - input $Q$, output $Q$. \n",
    " - `pt.rewrite.Bo1QueryExpansion(index)` - input $R$, output $Q$.\n",
    "\n",
    "Note that now, we're using BM25 instead of TF-IDF to retrieve documents.\n",
    "\n",
    "Transformers like `SDM` are performing query augmentation. Here, `SDM` is reweighting terms using a Dirichlet language model like we talked about in class. However, many query rewrites a possible! For example, we could use WordNet to expand the query with synonyms or even define our own. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 720,
     "status": "ok",
     "timestamp": 1616668415043,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "5nJHxh7A2dPP"
   },
   "outputs": [],
   "source": [
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
    "sdm = pt.rewrite.SDM()\n",
    "qe = pt.rewrite.Bo1QueryExpansion(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how `sdm` applies to a given query. This generates a query in an [Indri-like query language](https://www.lemurproject.org/lemur/IndriQueryLanguage.php) that Terrier (cf. `pt.BatchRetrieve()`) can understand.\n",
    " - `#combine()` - is used for weighting sub-expressions\n",
    " - `#1() - matches as a phrase, i.e. how many times do the constituent words exactly match as a phrase\n",
    " - `#uw8()` and `#uw12()` look for how many times the constituent words appear in unordered windows of 8 or 12 tokens.\n",
    " - finally, the weighting model is overridden for these query terms.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chemical reactions #combine:0=0.1:wmodel=org.terrier.matching.models.dependence.pBiL(#1(chemical reactions)) #combine:0=0.1:wmodel=org.terrier.matching.models.dependence.pBiL(#uw8(chemical reactions)) #combine:0=0.1:wmodel=org.terrier.matching.models.dependence.pBiL(#uw12(chemical reactions))'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdm.search(\"chemical reactions\").iloc[0][\"query\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVmde7NpJdTT"
   },
   "source": [
    "## Task 2.1: Creating Experiments to test Pipelines (3 points)\n",
    "\n",
    "Which kinds of rankers will perform better? We can answer this by creating an [Experiment](https://pyterrier.readthedocs.io/en/latest/experiments.html) that will compare sequential dependence model and Bo1 query expansion on TREC CORD19 with the BM25 baseline. We used Experiments in Part 1, so we'll expand this idea again here to test out different pipelines.\n",
    "\n",
    "**Your Task:** You will need to construct appropriate pipelines to compare each approach by considering the input and output datatypes of the `bm25`, `sdm` and `qe`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 927,
     "status": "ok",
     "timestamp": 1616668451894,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "TF24TZSb3bOo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuruge/opt/anaconda3/lib/python3.8/site-packages/pyterrier/datasets.py:430: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df.drop(df.columns.difference(['qid','query']), 1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "topics = cord19.get_topics(variant='title')\n",
    "qrels = cord19.get_qrels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 648,
     "status": "ok",
     "timestamp": 1616668453463,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "eqXox-g-JpUd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuruge/opt/anaconda3/lib/python3.8/site-packages/pyterrier/datasets.py:430: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df.drop(df.columns.difference(['qid','query']), 1, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>recip_rank</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>ndcg_cut_5</th>\n",
       "      <th>ndcg_cut_10</th>\n",
       "      <th>P_5</th>\n",
       "      <th>P_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BR(BM25)</td>\n",
       "      <td>0.181478</td>\n",
       "      <td>0.808759</td>\n",
       "      <td>0.373328</td>\n",
       "      <td>0.611724</td>\n",
       "      <td>0.583665</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Compose(&lt;pyterrier.rewrite.SDM object at 0x7fa...</td>\n",
       "      <td>0.181982</td>\n",
       "      <td>0.807438</td>\n",
       "      <td>0.373439</td>\n",
       "      <td>0.613116</td>\n",
       "      <td>0.586512</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Compose(Compose(BR(BM25), &lt;pyterrier.rewrite.B...</td>\n",
       "      <td>0.190398</td>\n",
       "      <td>0.814247</td>\n",
       "      <td>0.388397</td>\n",
       "      <td>0.619323</td>\n",
       "      <td>0.580906</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name       map  recip_rank  \\\n",
       "0                                           BR(BM25)  0.181478    0.808759   \n",
       "1  Compose(<pyterrier.rewrite.SDM object at 0x7fa...  0.181982    0.807438   \n",
       "2  Compose(Compose(BR(BM25), <pyterrier.rewrite.B...  0.190398    0.814247   \n",
       "\n",
       "       ndcg  ndcg_cut_5  ndcg_cut_10    P_5   P_10  \n",
       "0  0.373328    0.611724     0.583665  0.700  0.652  \n",
       "1  0.373439    0.613116     0.586512  0.700  0.656  \n",
       "2  0.388397    0.619323     0.580906  0.696  0.638  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelineSDM = sdm >> bm25\n",
    "pipelinQE = bm25 >> qe >> bm25\n",
    "pt.Experiment(\n",
    "    [bm25, pipelineSDM, pipelinQE],\n",
    "    cord19.get_topics(variant='title'),\n",
    "    cord19.get_qrels(),\n",
    "    eval_metrics=[\"map\", \"recip_rank\", \"ndcg\", \"ndcg_cut_5\", \"ndcg_cut_10\", \"P_5\", \"P_10\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2:  Reflection (2 points)\n",
    "\n",
    "Which approaches result in significant increases in NDCG and MAP? Is NDCG@10 also improved? Write 2-3 sentences why you think this is the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bo1 query expansion results in significant increases in MAP and NDCG, while the sequential dependence model only slightly improves MAP and NDCG.<br/>\n",
    "However, the Bo1 query expansion does not improves NDCG@10, while the sequential dependence model improves it a little."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bo1 query expansion model rewrite the query based on the occurences of terms in the feedback documents provided for each query. Therefore, this rewrite is done based on the statistics of all documents, which improves a lot in overall performance but performs worse in the first few retrieved documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aJrYP1TSLwY"
   },
   "source": [
    "# Learning to Rank\n",
    "\n",
    "Now that we have some idea how to build pipelines in PyTerrier, we'll continue our exploration by constructing and evaluating Learning to Rank pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSi3svV24mCs"
   },
   "source": [
    "Learning to rank is fundamentally a machine learning approach to IR. To work, we'll need to create _training data_ to learn our ranking model. We'll also want development (\"dev\") data to evaluate hyperparameters and test data to see how well it works. Our dataset doesn't by itself already have the data split into train, dev, and test, so we'll first need to do that.\n",
    "\n",
    "TREC Covid only has 50 topics, which isn't a lot for training in general. However, for a homework, 50 is sufficient to show you how it works. In this case, we'll split this 30 for training (60%), 5 for validation (10%), and 15 for evaluation (30%). In your projects, you'll want to test for statistical significance (i.e., is the improvement better than what could be expected by chance?) so we will also examine statistical significance, though we have limited data (15 topics) to do this with.\n",
    "\n",
    "When training our model, we will only re-rank the top 500 documents for each query, which is hopefully sufficient data for learning to rank. We don't set the model to rerank _all_ documents (though you can try this!) since it causes us to have to train the Learning to Rank model on all data and is often very slow in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 889,
     "status": "ok",
     "timestamp": 1616668500768,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "INvVKQz6K7SB"
   },
   "outputs": [],
   "source": [
    "RANK_CUTOFF = 10\n",
    "SEED=42\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tr_va_topics, test_topics = train_test_split(topics, test_size=15, random_state=SEED)\n",
    "train_topics, valid_topics =  train_test_split(tr_va_topics, test_size=5, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vftc_y-65VfA"
   },
   "source": [
    "## Defining a Feature Set for Learning to Rank\n",
    "\n",
    "Learning to Rank requires that we define which features to use in determining a ranking. We can use scores like BM25 but it's common to try adding more complex features that take advantage of what you, the IR practitioner, knows about the data or features that would be useful.\n",
    "\n",
    "For this part, we'll start with 7 features. PyTerrier provides [extensive support](https://pyterrier.readthedocs.io/en/latest/ltr.html#) for how to define features and calculate them for Learning to Rank. We recommend reading that documentation as you start to go over the code below. Note that several of these features will use more than just the text to compute relevance!\n",
    "\n",
    "1.   the BM25 abstract score;\n",
    "2.   sequential dependence model, scored by BM25;\n",
    "3.   does the abstract contain 'coronavirus covid', scored by BM25;\n",
    "4.   the BM25 score on the title (even though we didn't index it earlier!);\n",
    "5.   was the paper released/published in 2020? Recent papers were more useful for this task;\n",
    "6.   does the paper have a DOI, i.e. is it a formal publication?\n",
    "7.   the coordinate match score for the query--i.e. how many query terms appear in the abstract.\n",
    "\n",
    "Several of these feature require additional metadata `[\"title\", \"date\", \"doi\"]`, which is present in the TREC covid dataset. Fortunately, we can obtain this metadata after indexing using `pt.text.get_text(cord19, [\"title\", \"date\", \"doi\"])` to retrieve these extra metadata columns from the original data.\n",
    "\n",
    "There is a lot going on in this code block, but it's useful to think of this as _another_ example of operator overloading in PyTerrier. Here, we're combining features using the `**` operator, which is the [feature union](https://pyterrier.readthedocs.io/en/latest/ltr.html#calculating-features) operator in PyTerrier. \n",
    "\n",
    "The output of our feature union is the `ltr_feats1` object which is itself a transformer we can use to start ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 634,
     "status": "ok",
     "timestamp": 1616668557695,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "AYgwwrsPTGP1"
   },
   "outputs": [],
   "source": [
    "ltr_feats1 = (bm25 % RANK_CUTOFF) >> pt.text.get_text(cord19, [\"title\", \"date\", \"doi\"]) >> (\n",
    "    pt.transformer.IdentityTransformer()\n",
    "    ** # sequential dependence\n",
    "    (sdm >> bm25)\n",
    "    ** # score of text for query 'coronavirus covid'\n",
    "    (pt.apply.query(lambda row: 'coronavirus covid') >> bm25)\n",
    "    ** # score of title (not originally indexed)\n",
    "    (pt.text.scorer(body_attr=\"title\", takes='docs', wmodel='BM25') ) \n",
    "    ** # date 2020\n",
    "    (pt.apply.doc_score(lambda row: int(\"2020\" in row[\"date\"])))\n",
    "    ** # has doi\n",
    "    (pt.apply.doc_score(lambda row: int( row[\"doi\"] is not None and len(row[\"doi\"]) > 0) ))\n",
    "    ** # abstract coordinate match\n",
    "    pt.BatchRetrieve(index, wmodel=\"CoordinateMatch\")\n",
    ")\n",
    "\n",
    "# for reference, lets record the feature names here too\n",
    "fnames=[\"BM25\", \"SDM\", 'coronavirus covid', 'title', \"2020\", \"hasDoi\", \"CoordinateMatch\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nu3M9ujw6trC"
   },
   "source": [
    "To get a sense of what this process is doing, let's look at the output for the query \"coronavirus origin\". We can see that we now have extra document metadata columns `[\"title\", \"date\", \"doi\"]`, as well as the `\"features\"` column, which is what we'll use for learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "executionInfo": {
     "elapsed": 1000,
     "status": "ok",
     "timestamp": 1616668567796,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "OMG9kK9AUWI4",
    "outputId": "e4f6cbf8-4e89-46c8-b6c7-8d3e75eac2f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:42:55.854 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>doi</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>188321</td>\n",
       "      <td>8bn74f2z</td>\n",
       "      <td>0</td>\n",
       "      <td>20.541477</td>\n",
       "      <td>coronovirus origin</td>\n",
       "      <td>Reply to Comments on 'Co‐infection of SARS‐CoV...</td>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>10.1002/jmv.25838</td>\n",
       "      <td>[20.541476673741375, 20.541476673741375, 2.899...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>93090</td>\n",
       "      <td>ciqs6l7e</td>\n",
       "      <td>1</td>\n",
       "      <td>19.859401</td>\n",
       "      <td>coronovirus origin</td>\n",
       "      <td>The spread of the COVID-19 coronavirus: Health...</td>\n",
       "      <td>2020</td>\n",
       "      <td></td>\n",
       "      <td>[19.859401180444888, 19.859401180444888, 2.803...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>93091</td>\n",
       "      <td>qe9w4qbu</td>\n",
       "      <td>2</td>\n",
       "      <td>19.859401</td>\n",
       "      <td>coronovirus origin</td>\n",
       "      <td>The spread of the COVID-19 coronavirus: Health...</td>\n",
       "      <td>2020</td>\n",
       "      <td></td>\n",
       "      <td>[19.859401180444888, 19.859401180444888, 2.803...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>152453</td>\n",
       "      <td>egzztatj</td>\n",
       "      <td>3</td>\n",
       "      <td>19.459604</td>\n",
       "      <td>coronovirus origin</td>\n",
       "      <td>The spread of the COVID‐19 coronavirus: Health...</td>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>10.15252/embr.202050334</td>\n",
       "      <td>[19.459604473560834, 19.459604473560834, 2.747...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>105298</td>\n",
       "      <td>9ci1u50r</td>\n",
       "      <td>4</td>\n",
       "      <td>18.009391</td>\n",
       "      <td>coronovirus origin</td>\n",
       "      <td>Placental Pathology in Covid-19 Positive Mothe...</td>\n",
       "      <td>2020</td>\n",
       "      <td></td>\n",
       "      <td>[18.009390548413062, 18.009390548413062, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>175511</td>\n",
       "      <td>kdo2hir8</td>\n",
       "      <td>5</td>\n",
       "      <td>18.009391</td>\n",
       "      <td>coronovirus origin</td>\n",
       "      <td>Placental Pathology in Covid-19 Positive Mothe...</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>10.1177/1093526620925569</td>\n",
       "      <td>[18.009390548413062, 18.009390548413062, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>97984</td>\n",
       "      <td>76laky91</td>\n",
       "      <td>6</td>\n",
       "      <td>16.673852</td>\n",
       "      <td>coronovirus origin</td>\n",
       "      <td>Cross-species transmission of the newly identi...</td>\n",
       "      <td>2020</td>\n",
       "      <td></td>\n",
       "      <td>[16.67385232414447, 16.67385232414447, 3.37300...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>97985</td>\n",
       "      <td>niytf3wo</td>\n",
       "      <td>7</td>\n",
       "      <td>16.673852</td>\n",
       "      <td>coronovirus origin</td>\n",
       "      <td>Cross-species transmission of the newly identi...</td>\n",
       "      <td>2020</td>\n",
       "      <td></td>\n",
       "      <td>[16.67385232414447, 16.67385232414447, 3.37300...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>97986</td>\n",
       "      <td>262bcl7h</td>\n",
       "      <td>8</td>\n",
       "      <td>16.673852</td>\n",
       "      <td>coronovirus origin</td>\n",
       "      <td>Cross-species transmission of the newly identi...</td>\n",
       "      <td>2020</td>\n",
       "      <td></td>\n",
       "      <td>[16.67385232414447, 16.67385232414447, 3.37300...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>97987</td>\n",
       "      <td>nip1ax1x</td>\n",
       "      <td>9</td>\n",
       "      <td>16.673852</td>\n",
       "      <td>coronovirus origin</td>\n",
       "      <td>Cross-species transmission of the newly identi...</td>\n",
       "      <td>2020</td>\n",
       "      <td></td>\n",
       "      <td>[16.67385232414447, 16.67385232414447, 3.37300...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid   docid     docno  rank      score               query  \\\n",
       "0   1  188321  8bn74f2z     0  20.541477  coronovirus origin   \n",
       "1   1   93090  ciqs6l7e     1  19.859401  coronovirus origin   \n",
       "2   1   93091  qe9w4qbu     2  19.859401  coronovirus origin   \n",
       "3   1  152453  egzztatj     3  19.459604  coronovirus origin   \n",
       "4   1  105298  9ci1u50r     4  18.009391  coronovirus origin   \n",
       "5   1  175511  kdo2hir8     5  18.009391  coronovirus origin   \n",
       "6   1   97984  76laky91     6  16.673852  coronovirus origin   \n",
       "7   1   97985  niytf3wo     7  16.673852  coronovirus origin   \n",
       "8   1   97986  262bcl7h     8  16.673852  coronovirus origin   \n",
       "9   1   97987  nip1ax1x     9  16.673852  coronovirus origin   \n",
       "\n",
       "                                               title        date  \\\n",
       "0  Reply to Comments on 'Co‐infection of SARS‐CoV...  2020-04-08   \n",
       "1  The spread of the COVID-19 coronavirus: Health...        2020   \n",
       "2  The spread of the COVID-19 coronavirus: Health...        2020   \n",
       "3  The spread of the COVID‐19 coronavirus: Health...  2020-03-17   \n",
       "4  Placental Pathology in Covid-19 Positive Mothe...        2020   \n",
       "5  Placental Pathology in Covid-19 Positive Mothe...  2020-05-12   \n",
       "6  Cross-species transmission of the newly identi...        2020   \n",
       "7  Cross-species transmission of the newly identi...        2020   \n",
       "8  Cross-species transmission of the newly identi...        2020   \n",
       "9  Cross-species transmission of the newly identi...        2020   \n",
       "\n",
       "                        doi                                           features  \n",
       "0         10.1002/jmv.25838  [20.541476673741375, 20.541476673741375, 2.899...  \n",
       "1                            [19.859401180444888, 19.859401180444888, 2.803...  \n",
       "2                            [19.859401180444888, 19.859401180444888, 2.803...  \n",
       "3   10.15252/embr.202050334  [19.459604473560834, 19.459604473560834, 2.747...  \n",
       "4                            [18.009390548413062, 18.009390548413062, 0.0, ...  \n",
       "5  10.1177/1093526620925569  [18.009390548413062, 18.009390548413062, 0.0, ...  \n",
       "6                            [16.67385232414447, 16.67385232414447, 3.37300...  \n",
       "7                            [16.67385232414447, 16.67385232414447, 3.37300...  \n",
       "8                            [16.67385232414447, 16.67385232414447, 3.37300...  \n",
       "9                            [16.67385232414447, 16.67385232414447, 3.37300...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltr_feats1.search(\"coronovirus origin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vQNbSSgJCmC"
   },
   "source": [
    "We can also look at the raw feature values themselves too. Here, we'll look at the features for the first document. Note that the BM25 in the \"score\" column above is also the first value in the feature array (20.54), because we used an identity transformer, which returns the same value as its input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1006,
     "status": "ok",
     "timestamp": 1616668573072,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "EzVDLL8pI_gR",
    "outputId": "ff60a8d3-ebc0-4d1b-b87d-0e6245ad7553"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:43:08.915 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([20.54147667, 20.54147667,  2.89976767,  0.        ,  1.        ,\n",
       "        1.        ,  1.        ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltr_feats1.search(\"coronovirus origin\").iloc[0][\"features\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Od8P-N4E7QTk"
   },
   "source": [
    "## Actually Doing the Learning for Learning to Rank\n",
    "\n",
    "In class, we talked about three types of Learning to rank: pointwise, pairwise, and listwise. Here, we'll train a few models for two of these types, listwise and pointwise. \n",
    "\n",
    " - coordinate ascent from FastRank, a listwise linear technique\n",
    " - random forests from `scikit-learn`, a pointwise regression tree technique\n",
    " - LambdaMART from LightGBM, a listwise regression tree technique\n",
    "\n",
    "We can use the same feature pipeline, `ltr_feats1`, with all three.  To train the ranker, we compose it (`>>`) with the learned model. We use `pt.ltr.apply_learned_model()` which knows how to deal with different learners.\n",
    "\n",
    "The full pipeline is then fitted (learned) using `.fit()`, specifying the training topics and qrels, much like how we train models with Scikit-Learn. Importantly, the preceding stages of the pipeline (retrieval and feature calculation) are applied to the training topics in order to obtain the results, which are then passed to the learning to rank technique. LightGBM has early stopping enabled, which uses a validation topics set--similarly the validation topics are transformed into validation results.\n",
    "\n",
    "Finally, `%time` is notebook \"magic command\" specific to Juypyter which displays how long learning takes for each technique. Learning for each technique takes under 30 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastrank\n",
      "  Downloading fastrank-0.7.0-py3-none-macosx_10_7_x86_64.whl (853 kB)\n",
      "\u001b[K     |████████████████████████████████| 853 kB 4.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cffi in /Users/xuruge/opt/anaconda3/lib/python3.8/site-packages (from fastrank) (1.14.3)\n",
      "Requirement already satisfied: attrs in /Users/xuruge/opt/anaconda3/lib/python3.8/site-packages (from fastrank) (20.3.0)\n",
      "Requirement already satisfied: numpy in /Users/xuruge/opt/anaconda3/lib/python3.8/site-packages (from fastrank) (1.19.2)\n",
      "Requirement already satisfied: pycparser in /Users/xuruge/opt/anaconda3/lib/python3.8/site-packages (from cffi->fastrank) (2.20)\n",
      "Installing collected packages: fastrank\n",
      "Successfully installed fastrank-0.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install fastrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23178,
     "status": "ok",
     "timestamp": 1616668669944,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "OFPZ39eSYIXV",
    "outputId": "0c3e398c-ae14-4fce-8d94-703151d53ad0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:48:01.575 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuruge/opt/anaconda3/lib/python3.8/site-packages/pyterrier/transformer.py:760: UserWarning: Got number of results different expected from <pyterrier.batchretrieve.TextScorer object at 0x7faae374f040>, expected 300 received 304, feature scores for any missing documents be 0, extraneous documents will be removed\n",
      "  warn(\"Got number of results different expected from %s, expected %d received %d, feature scores for any missing documents be 0, extraneous documents will be removed\" % (repr(m), num_results, len(res)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 7s, sys: 871 ms, total: 1min 8s\n",
      "Wall time: 25.9 s\n"
     ]
    }
   ],
   "source": [
    "import fastrank\n",
    "\n",
    "train_request = fastrank.TrainRequest.coordinate_ascent()\n",
    "\n",
    "params = train_request.params\n",
    "params.init_random = True\n",
    "params.normalize = True\n",
    "params.seed = 1234567\n",
    "\n",
    "ca_pipe = ltr_feats1 >> pt.ltr.apply_learned_model(train_request, form='fastrank')\n",
    "\n",
    "%time ca_pipe.fit(train_topics, cord19.get_qrels())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try learning a different pointwise model to estimate relevance scores using a Random Forest model from Scikit-Learn. This is a good example of how we can use off-the-shelf regression models in PyTerrier to perform learning to rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9897,
     "status": "ok",
     "timestamp": 1616668679862,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "T0SpZ13wUagq",
    "outputId": "c3fdfa85-bad7-47d0-b95b-f51ba9d35efb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:48:32.978 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    2.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 s, sys: 278 ms, total: 12.3 s\n",
      "Wall time: 8.87 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    4.4s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=400, verbose=1, random_state=SEED, n_jobs=2)\n",
    "\n",
    "rf_pipe = ltr_feats1 >> pt.ltr.apply_learned_model(rf)\n",
    "\n",
    "%time rf_pipe.fit(train_topics, cord19.get_qrels())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's use a list-wise approach, which typically performs best among the three types of Learning to Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: fastrank in /Users/xuruge/opt/anaconda3/lib/python3.8/site-packages (0.7.0)\n",
      "Collecting lightgbm==3.1.1\n",
      "  Downloading lightgbm-3.1.1-py2.py3-none-macosx_10_13_x86_64.macosx_10_14_x86_64.macosx_10_15_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: attrs in /Users/xuruge/opt/anaconda3/lib/python3.8/site-packages (from fastrank) (20.3.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /Users/xuruge/opt/anaconda3/lib/python3.8/site-packages (from fastrank) (1.19.2)\n",
      "Requirement already satisfied, skipping upgrade: cffi in /Users/xuruge/opt/anaconda3/lib/python3.8/site-packages (from fastrank) (1.14.3)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn!=0.22.0 in /Users/xuruge/opt/anaconda3/lib/python3.8/site-packages (from lightgbm==3.1.1) (0.24.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy in /Users/xuruge/opt/anaconda3/lib/python3.8/site-packages (from lightgbm==3.1.1) (1.7.1)\n",
      "Requirement already satisfied, skipping upgrade: wheel in /Users/xuruge/opt/anaconda3/lib/python3.8/site-packages (from lightgbm==3.1.1) (0.35.1)\n",
      "Requirement already satisfied, skipping upgrade: pycparser in /Users/xuruge/opt/anaconda3/lib/python3.8/site-packages (from cffi->fastrank) (2.20)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /Users/xuruge/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn!=0.22.0->lightgbm==3.1.1) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /Users/xuruge/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn!=0.22.0->lightgbm==3.1.1) (0.17.0)\n",
      "Installing collected packages: lightgbm\n",
      "  Attempting uninstall: lightgbm\n",
      "    Found existing installation: lightgbm 3.3.1\n",
      "    Uninstalling lightgbm-3.3.1:\n",
      "      Successfully uninstalled lightgbm-3.3.1\n",
      "Successfully installed lightgbm-3.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade fastrank lightgbm==3.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8930,
     "status": "ok",
     "timestamp": 1616668695125,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "u0jb1jw_VdWU",
    "outputId": "1d658e08-07d7-4753-cc79-a987ebafc6ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:00:52.737 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuruge/opt/anaconda3/lib/python3.8/site-packages/pyterrier/transformer.py:760: UserWarning: Got number of results different expected from <pyterrier.batchretrieve.TextScorer object at 0x7faae374f040>, expected 300 received 304, feature scores for any missing documents be 0, extraneous documents will be removed\n",
      "  warn(\"Got number of results different expected from %s, expected %d received %d, feature scores for any missing documents be 0, extraneous documents will be removed\" % (repr(m), num_results, len(res)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:00:54.551 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuruge/opt/anaconda3/lib/python3.8/site-packages/pyterrier/transformer.py:760: UserWarning: Got number of results different expected from <pyterrier.batchretrieve.TextScorer object at 0x7faae374f040>, expected 50 received 54, feature scores for any missing documents be 0, extraneous documents will be removed\n",
      "  warn(\"Got number of results different expected from %s, expected %d received %d, feature scores for any missing documents be 0, extraneous documents will be removed\" % (repr(m), num_results, len(res)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] early_stopping_round is set=5, early_stopping_rounds=5 will be ignored. Current value: early_stopping_round=5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuruge/opt/anaconda3/lib/python3.8/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  for alias in _ConfigAliases.get(\"num_iterations\"):\n",
      "/Users/xuruge/opt/anaconda3/lib/python3.8/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  for alias in _ConfigAliases.get(\"early_stopping_round\"):\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "Number of rows 32776 exceeds upper limit of 10000 for a query",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyterrier/transformer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, topics_or_res_tr, qrels_tr, topics_or_res_va, qrels_va)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEstimatorBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopics_or_res_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqrels_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopics_or_res_va\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqrels_va\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mtopics_or_res_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopics_or_res_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyterrier/ltr.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, topics_and_results_Train, qrelsTrain, topics_and_results_Valid, qrelsValid)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         self.learner.fit(\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtr_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"qid\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"docno\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# we name group here for lightgbm compat.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_group, eval_metric, eval_at, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    981\u001b[0m                                     \u001b[0meval_init_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_init_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_group\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m                                     \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m                                     \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m                                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m                                     \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m             raise ValueError(\"Number of features of the model must \"\n\u001b[0m\u001b[1;32m    684\u001b[0m                              \u001b[0;34m\"match the input. Model n_features_ is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0mcallbacks_before_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks_before_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'order'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0mcallbacks_after_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks_after_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'order'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m     \u001b[0;31m# construct booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[1;32m   2232\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'There are no trees in this Booster and thus nothing to parse'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2234\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0m_is_split_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2235\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m'split_index'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromiter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected double pointer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLightGBMError\u001b[0m: Number of rows 32776 exceeds upper limit of 10000 for a query"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# this configures LightGBM as LambdaMART\n",
    "lmart_l = lgb.LGBMRanker(\n",
    "    task=\"train\",\n",
    "    silent=False,\n",
    "    min_data_in_leaf=1,\n",
    "    min_sum_hessian_in_leaf=1,\n",
    "    max_bin=255,\n",
    "    num_leaves=31,\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    ndcg_eval_at=[10],\n",
    "    ndcg_at=[10],\n",
    "    eval_at=[10],\n",
    "    learning_rate= .1,\n",
    "    importance_type=\"gain\",\n",
    "    num_iterations=100,\n",
    "    early_stopping_rounds=5\n",
    ")\n",
    "\n",
    "lmart_x_pipe = ltr_feats1 >> pt.ltr.apply_learned_model(lmart_l, form=\"ltr\", fit_kwargs={'eval_at':[10]})\n",
    "\n",
    "%time lmart_x_pipe.fit(train_topics, cord19.get_qrels(), valid_topics, cord19.get_qrels())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7rNqB7sBKFB"
   },
   "source": [
    "## Evaluating all the solutions \n",
    "\n",
    "We've fit the three Learning to Rank models so we can now use them to predict relevance scores for the held-out 15 topics (queries) in our test set. Note that if we wanted to do any tuning (e.g., pick the number of leaves in our `RandomForestRegressor`, we could run this evaluation on our held-out _dev_ set and pick the hyperparameters that produced best performance on it).\n",
    "\n",
    "### Task 3: Create an experiment to compare (5 points)\n",
    "\n",
    "Create a new `Experiment` to compare our three solutions and BM25 at the `RANK_CUTOFF` (four models in total). Report MAP, NDCG, and NDCG@10 measures and one new measure: mean response time (`\"mrt\"`), which will tell us how fast the models are able to score documents--something important if we're going to use them in the real world!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "executionInfo": {
     "elapsed": 8964,
     "status": "ok",
     "timestamp": 1616668732099,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "P0EhTwejVqev",
    "outputId": "3393cb4e-2a2e-4e92-ede5-5857457ca863"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmGe5rniC_Pn"
   },
   "source": [
    "Thats really interesting – all three learned models could improve NDCG@10 over BM25, but the coordinate ascent model improved the most (significantly so on all three metrics, but again on only 15 queries). Coordinate Ascent improved upto 10 queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ov0JjWGEbrT"
   },
   "source": [
    "## Analysis: What Features Matter?\n",
    "\n",
    "Since we're _learning_ a ranking model, we can inspect that model to see what information it's using. One option for inspecting the model is to evaluate the performance of each feature independently to see how much it contributes to the eventual relevance. To examine each feature, we will create separate a separate model from each feature in our feature pipeline (`ltr_feats1`) by using `pt.ltr.feature_to_score(i)` with a particular feature number $i$. In essence, this will only score the relevance using a single feature's values, even though we've already calculated all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "executionInfo": {
     "elapsed": 17063,
     "status": "ok",
     "timestamp": 1616668775186,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "7nCb9U7uvszV",
    "outputId": "ea79739f-9155-4343-9f7d-62a5d523ebcd"
   },
   "outputs": [],
   "source": [
    "pt.Experiment(\n",
    "    [ltr_feats1 >> pt.ltr.feature_to_score(i) for i in range(len(fnames))],\n",
    "    test_topics,\n",
    "    qrels, \n",
    "    names=fnames,\n",
    "    eval_metrics=[\"map\", \"ndcg\", \"ndcg_cut_10\", \"num_rel_ret\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rU7YYKFSFeke"
   },
   "source": [
    "### Inspecting the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjaWBEo8HA20"
   },
   "source": [
    "To get a sense of feature importance, we can also analyze the learned models themselves using their internal feature weights in the Scikit-Learn models. Here, we'll plot the feature importances in a few ways. For the coordinate ascent model, we plot the feature weights (note the log-scale y-axis); while for the regression-tree based techniques, we report the feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "executionInfo": {
     "elapsed": 2333,
     "status": "ok",
     "timestamp": 1616668777541,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "CdOP1b8Cjp44",
    "outputId": "e2da7f44-21de-4fc0-a6f5-50c3285b6525"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt, numpy as np\n",
    "\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(1, 3, figsize=(10, 6))\n",
    "\n",
    "ax0.bar(np.arange(len(fnames)), ca_pipe[1].model.to_dict()['Linear']['weights'])\n",
    "ax0.set_xticks(np.arange(len(fnames)))\n",
    "ax0.set_xticklabels(fnames, rotation=45, ha='right')\n",
    "ax0.set_title(\"Coordinate Ascent\\n Feature Weights\")\n",
    "ax0.set_yscale('log')\n",
    "\n",
    "ax1.bar(np.arange(len(fnames)), rf.feature_importances_)\n",
    "ax1.set_xticks(np.arange(len(fnames)))\n",
    "ax1.set_xticklabels(fnames, rotation=45, ha='right')\n",
    "ax1.set_title(\"Random Forests\\n Feature Importance\")\n",
    "\n",
    "ax2.bar(np.arange(len(fnames)), lmart_l.feature_importances_)\n",
    "ax2.set_xticks(np.arange(len(fnames)))\n",
    "ax2.set_xticklabels(fnames, rotation=45, ha='right')\n",
    "ax2.set_title(\"$\\lambda$MART\\n Feature Importance\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HhGDiPLHO7v"
   },
   "source": [
    "## Task 4: Adding new features (15 points)\n",
    "\n",
    "We've seen how to develop Learning to Rank models and analyze features. Your task is the following:\n",
    "\n",
    "  - Define _at least_ two additional features to use in learning to rank models. These can be functions that you define or additional options from PyTerrier\n",
    "  - Include your new features in a new learning to rank pipeline using the three approaches we have above to create three new models\n",
    "  - Evaluate your new models against the old models in an Experiment\n",
    " \n",
    "**Full credit will depend on one of your new models outperforming the best of the initial three models.**\n",
    "\n",
    "You should aim to evaluate your features initially on the `dev` set, rather than the `test` set in order to avoid overfitting your features (i.e., never look at the test set until the end). You can use the feature and model inspection code to give you some idea of what the model is looking at. We also recommend looking at the data directly to think about what kinds of features might be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ECIR 2021 Tutorial Notebook - Part 2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "224e088c2ac64cc29b1d78a5e850ebe4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3cc8a8231dc44c768dffbc755dd0f2fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "cord19/trec-covid documents: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_587cc3f3700b4201b750e8fd3408e34d",
      "max": 192509,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ae5b4e71f7a74bb8aaa7c8bf1e985993",
      "value": 192509
     }
    },
    "562458b5bd6d4bb3a629932a2edc54d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3cc8a8231dc44c768dffbc755dd0f2fb",
       "IPY_MODEL_d998ea1d78fa458d94e3107bc2a514b5"
      ],
      "layout": "IPY_MODEL_224e088c2ac64cc29b1d78a5e850ebe4"
     }
    },
    "587cc3f3700b4201b750e8fd3408e34d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae5b4e71f7a74bb8aaa7c8bf1e985993": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c6b946af922e4b248a5bfecd99e11a8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d998ea1d78fa458d94e3107bc2a514b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eb34c2ee16c241ea955bb088632f603d",
      "placeholder": "​",
      "style": "IPY_MODEL_c6b946af922e4b248a5bfecd99e11a8c",
      "value": " 192509/192509 [06:11&lt;00:00, 518.22it/s]"
     }
    },
    "eb34c2ee16c241ea955bb088632f603d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
