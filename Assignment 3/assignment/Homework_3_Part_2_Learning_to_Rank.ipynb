{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework 3 Part 2 - Learning to Rank.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Oe730o8rzyn"
      },
      "source": [
        "# SI 650 / EECS 549: Homework 3 Part 2\n",
        "\n",
        "Homework 3 Part 2 will have you working with Learning to Rank approaches, which as we've seen are highly competitive when enough data is available. Part 2 should be completed after Part 1 and will use some small parts of that code to construct an index and load data.\n",
        "\n",
        "If you haven't worked with them before, Part 2 will expose you to [overloaded python operators](https://www.geeksforgeeks.org/operator-overloading-in-python/), which will let you call functions using alternative python syntax. For example, if you're using two Python `list` objects, you can interact with them using `+` to call the equivalent method. \n",
        "\n",
        "In Part 2, you'll work on the following tasks:\n",
        " - Construct and learn learning-to-rank pipelines\n",
        " - Add new features for learning-to-rank\n",
        " - Evaluate learning-to-rank models\n",
        " \n",
        "Part 2 can be run on most laptops as well. Some of the machine learning models may take a few minutes to train but you are also welcome to run these on Great Lakes. None of the code in this part involves deep learning or requires a GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0edvI3LDtOym"
      },
      "source": [
        "### Launch PyTerrier\n",
        "Import the packages you need and launch PyTerrier like we did in Part 1. You will still need to make sure `JAVA_HOME` is set for this part."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Fnbt-MBGwQS",
        "outputId": "dccb2845-eac1-4691-ac40-96efc68685bc"
      },
      "source": [
        "!pip install --upgrade fastrank lightgbm==3.1.1\n",
        "!pip install python-terrier"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastrank in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: lightgbm==3.1.1 in /usr/local/lib/python3.7/dist-packages (3.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightgbm==3.1.1) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0 in /usr/local/lib/python3.7/dist-packages (from lightgbm==3.1.1) (1.0.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lightgbm==3.1.1) (1.4.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm==3.1.1) (0.37.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.22.0->lightgbm==3.1.1) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.22.0->lightgbm==3.1.1) (1.1.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from fastrank) (21.2.0)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fastrank) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fastrank) (2.21)\n",
            "Requirement already satisfied: python-terrier in /usr/local/lib/python3.7/dist-packages (0.7.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from python-terrier) (1.1.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from python-terrier) (2.23.0)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (from python-terrier) (3.2)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from python-terrier) (8.11.0)\n",
            "Requirement already satisfied: nptyping in /usr/local/lib/python3.7/dist-packages (from python-terrier) (1.4.4)\n",
            "Requirement already satisfied: deprecation in /usr/local/lib/python3.7/dist-packages (from python-terrier) (2.1.0)\n",
            "Requirement already satisfied: pyjnius~=1.3.0 in /usr/local/lib/python3.7/dist-packages (from python-terrier) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from python-terrier) (1.19.5)\n",
            "Requirement already satisfied: matchpy in /usr/local/lib/python3.7/dist-packages (from python-terrier) (0.5.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from python-terrier) (2.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from python-terrier) (4.62.3)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from python-terrier) (0.0)\n",
            "Requirement already satisfied: chest in /usr/local/lib/python3.7/dist-packages (from python-terrier) (0.2.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from python-terrier) (0.3.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from python-terrier) (1.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from python-terrier) (1.1.0)\n",
            "Requirement already satisfied: ir-datasets>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from python-terrier) (0.4.3)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from python-terrier) (0.10.2)\n",
            "Requirement already satisfied: ir-measures>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from python-terrier) (0.2.1)\n",
            "Requirement already satisfied: trec-car-tools>=2.5.4 in /usr/local/lib/python3.7/dist-packages (from ir-datasets>=0.3.2->python-terrier) (2.5.4)\n",
            "Requirement already satisfied: zlib-state>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from ir-datasets>=0.3.2->python-terrier) (0.1.3)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from ir-datasets>=0.3.2->python-terrier) (4.6.3)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from ir-datasets>=0.3.2->python-terrier) (6.0)\n",
            "Requirement already satisfied: lz4>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from ir-datasets>=0.3.2->python-terrier) (3.1.3)\n",
            "Requirement already satisfied: pyautocorpus>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from ir-datasets>=0.3.2->python-terrier) (0.1.6)\n",
            "Requirement already satisfied: ijson>=3.1.3 in /usr/local/lib/python3.7/dist-packages (from ir-datasets>=0.3.2->python-terrier) (3.1.4)\n",
            "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.7/dist-packages (from ir-datasets>=0.3.2->python-terrier) (4.6.4)\n",
            "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.5)\n",
            "Requirement already satisfied: warc3-wet>=0.2.3 in /usr/local/lib/python3.7/dist-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.3)\n",
            "Requirement already satisfied: cwl-eval>=1.0.10 in /usr/local/lib/python3.7/dist-packages (from ir-measures>=0.2.0->python-terrier) (1.0.10)\n",
            "Requirement already satisfied: pytrec-eval-terrier==0.5.1 in /usr/local/lib/python3.7/dist-packages (from ir-measures>=0.2.0->python-terrier) (0.5.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from pyjnius~=1.3.0->python-terrier) (0.29.24)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from pyjnius~=1.3.0->python-terrier) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->python-terrier) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->python-terrier) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->python-terrier) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->python-terrier) (2.10)\n",
            "Requirement already satisfied: cbor>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from trec-car-tools>=2.5.4->ir-datasets>=0.3.2->python-terrier) (1.0.0)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from chest->python-terrier) (1.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from deprecation->python-terrier) (21.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->python-terrier) (2.0.1)\n",
            "Requirement already satisfied: multiset<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from matchpy->python-terrier) (2.1.1)\n",
            "Requirement already satisfied: typish>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from nptyping->python-terrier) (1.9.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->deprecation->python-terrier) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->python-terrier) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->python-terrier) (2018.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->python-terrier) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->python-terrier) (3.0.0)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->python-terrier) (0.5.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkCdrWdRzS64"
      },
      "source": [
        "import pyterrier as pt\n",
        "import pandas as pd\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWc4UQgX6vDD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fb6907c-24ed-4842-becf-6d2a29bb5075"
      },
      "source": [
        "if not pt.started():\n",
        "    pt.init()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTerrier 0.7.1 has loaded Terrier 5.6 (built by craigmacdonald on 2021-09-17 13:27)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p18d1tpJvD_5"
      },
      "source": [
        "# Indexing CORD19\n",
        "\n",
        "Like in Part 1, we'll again use the CORD19 data. However, **in Part 2, we will add in positional indexing.** This code will still look very similar to your code from Part 1. When creating the index, add the `blocks=True` argument, which will include word order information in the index. On most laptops, this process will take ~1 minute.\n",
        "\n",
        "You may see an error `java.io.IOException: Key 8lqzfj2e is not unique: 37597,11755` during indexing but you can safely ignore the error for the purposes of this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9E6oLubIeI4"
      },
      "source": [
        "cord19 = pt.datasets.get_dataset('irds:cord19/trec-covid')\n",
        "pt_index_path = './terrier_trec_covid_positional_indices'\n",
        "\n",
        "if not os.path.exists(pt_index_path + \"/data.properties\"):\n",
        "    # create the index, using the IterDictIndexer indexer \n",
        "    indexer = pt.IterDictIndexer(pt_index_path, blocks=True)\n",
        "\n",
        "    # we give the dataset get_corpus_iter() directly to the indexer\n",
        "    # while specifying the fields to index and the metadata to record\n",
        "    index_ref = indexer.index(cord19.get_corpus_iter(), fields=('abstract',), meta=('docno',))\n",
        "\n",
        "else:\n",
        "    # if you already have the index, use it.\n",
        "    index_ref = pt.IndexRef.of(pt_index_path + \"/data.properties\")\n",
        "\n",
        "index = pt.IndexFactory.of(index_ref)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiM8I_fkUcQ9"
      },
      "source": [
        "## Transformers and Operators\n",
        "\n",
        "PyTerrier works extensively with objects/functions that _transform_ one input to another. We saw this behavior with the `BatchRetrieve` object that we used earlier to get search results, which had a `transform()` method that takes as input a dataframe, and returns another dataframe. We can think of this function as a *transformation* of the earlier dataframe (e.g., transforming the queries into results). PyTerrier has many such functions that act as  [transformers](https://pyterrier.readthedocs.io/en/latest/transformer.html). \n",
        "\n",
        "Let's use the transformer, `BatchRetrieve`, and this time specify that we'll use the TF-IDF word model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqMt-9UlTqLa"
      },
      "source": [
        "tfidf = pt.BatchRetrieve(index, wmodel=\"TF_IDF\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GW3afDgPukvU"
      },
      "source": [
        "In PyTerrier, all transformers have been coded so that they be combined using Python operators, which is an example  of operator overloading. If we want to have the output of one transformer used as the input of another transformer, we can use the `>>` operator. This operator lets us compose a series of transformations to output our document rankings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "e9HkXxtgug15",
        "outputId": "a0e75ec5-8a6a-4d07-8cdc-15879ffa5fe4"
      },
      "source": [
        "# This is our first retrieval transformer, which transforms a queries dataframe to a results dataframe\n",
        "tf = pt.BatchRetrieve(index, wmodel=\"Tf\")\n",
        "\n",
        "tf( cord19.get_topics(variant='title').head(1) )"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>docid</th>\n",
              "      <th>docno</th>\n",
              "      <th>rank</th>\n",
              "      <th>score</th>\n",
              "      <th>query</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>146967</td>\n",
              "      <td>jkrj0lbm</td>\n",
              "      <td>0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>coronavirus origin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>25564</td>\n",
              "      <td>jlzncyax</td>\n",
              "      <td>1</td>\n",
              "      <td>18.0</td>\n",
              "      <td>coronavirus origin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>45549</td>\n",
              "      <td>8l411r1w</td>\n",
              "      <td>2</td>\n",
              "      <td>15.0</td>\n",
              "      <td>coronavirus origin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>29359</td>\n",
              "      <td>gnxbfcod</td>\n",
              "      <td>3</td>\n",
              "      <td>14.0</td>\n",
              "      <td>coronavirus origin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>63537</td>\n",
              "      <td>cpc6v40g</td>\n",
              "      <td>4</td>\n",
              "      <td>14.0</td>\n",
              "      <td>coronavirus origin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>1</td>\n",
              "      <td>58583</td>\n",
              "      <td>wfcyaumm</td>\n",
              "      <td>995</td>\n",
              "      <td>4.0</td>\n",
              "      <td>coronavirus origin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>1</td>\n",
              "      <td>59153</td>\n",
              "      <td>86vu0kjm</td>\n",
              "      <td>996</td>\n",
              "      <td>4.0</td>\n",
              "      <td>coronavirus origin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>1</td>\n",
              "      <td>59343</td>\n",
              "      <td>9n733bet</td>\n",
              "      <td>997</td>\n",
              "      <td>4.0</td>\n",
              "      <td>coronavirus origin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>1</td>\n",
              "      <td>59478</td>\n",
              "      <td>mx58ai55</td>\n",
              "      <td>998</td>\n",
              "      <td>4.0</td>\n",
              "      <td>coronavirus origin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>1</td>\n",
              "      <td>59875</td>\n",
              "      <td>d0x23frk</td>\n",
              "      <td>999</td>\n",
              "      <td>4.0</td>\n",
              "      <td>coronavirus origin</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    qid   docid     docno  rank  score               query\n",
              "0     1  146967  jkrj0lbm     0   25.0  coronavirus origin\n",
              "1     1   25564  jlzncyax     1   18.0  coronavirus origin\n",
              "2     1   45549  8l411r1w     2   15.0  coronavirus origin\n",
              "3     1   29359  gnxbfcod     3   14.0  coronavirus origin\n",
              "4     1   63537  cpc6v40g     4   14.0  coronavirus origin\n",
              "..   ..     ...       ...   ...    ...                 ...\n",
              "995   1   58583  wfcyaumm   995    4.0  coronavirus origin\n",
              "996   1   59153  86vu0kjm   996    4.0  coronavirus origin\n",
              "997   1   59343  9n733bet   997    4.0  coronavirus origin\n",
              "998   1   59478  mx58ai55   998    4.0  coronavirus origin\n",
              "999   1   59875  d0x23frk   999    4.0  coronavirus origin\n",
              "\n",
              "[1000 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gz5sY2hVGC5r"
      },
      "source": [
        "Let's define our first pipeline using the `>>` operator. If we have two transformers, `a` and `b`, the result of `a >> b` is itself a transformer!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHHIn-rMvk_5"
      },
      "source": [
        "pipeline = tf >> tfidf"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIOr-vsaGC5s"
      },
      "source": [
        "We can use this pipeline like any other transformer. Here, we'll  pass in the very first query using `head(1)` and get the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIDCwyrlGC5s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "73c0cc15-0bc5-47fa-c2ae-75314b10bdb6"
      },
      "source": [
        "pipeline(cord19.get_topics(variant='title').head(1))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>docid</th>\n",
              "      <th>docno</th>\n",
              "      <th>rank</th>\n",
              "      <th>score</th>\n",
              "      <th>query</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>175892</td>\n",
              "      <td>zy8qjaai</td>\n",
              "      <td>0</td>\n",
              "      <td>7.080599</td>\n",
              "      <td>coronavirus origin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>82224</td>\n",
              "      <td>8ccl9aui</td>\n",
              "      <td>1</td>\n",
              "      <td>6.775667</td>\n",
              "      <td>coronavirus origin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>135326</td>\n",
              "      <td>ne5r4d4b</td>\n",
              "      <td>2</td>\n",
              "      <td>6.683114</td>\n",
              "      <td>coronavirus origin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>93245</td>\n",
              "      <td>hmvo5b0q</td>\n",
              "      <td>3</td>\n",
              "      <td>6.507303</td>\n",
              "      <td>coronavirus origin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>84953</td>\n",
              "      <td>ax6v6ham</td>\n",
              "      <td>4</td>\n",
              "      <td>6.483723</td>\n",
              "      <td>coronavirus origin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>1</td>\n",
              "      <td>136214</td>\n",
              "      <td>ygnxmcl1</td>\n",
              "      <td>995</td>\n",
              "      <td>1.640752</td>\n",
              "      <td>coronavirus origin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>1</td>\n",
              "      <td>91270</td>\n",
              "      <td>853ipgea</td>\n",
              "      <td>996</td>\n",
              "      <td>1.634118</td>\n",
              "      <td>coronavirus origin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>1</td>\n",
              "      <td>146556</td>\n",
              "      <td>oshov14d</td>\n",
              "      <td>997</td>\n",
              "      <td>1.634118</td>\n",
              "      <td>coronavirus origin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>1</td>\n",
              "      <td>32462</td>\n",
              "      <td>xtfjw1ag</td>\n",
              "      <td>998</td>\n",
              "      <td>1.592462</td>\n",
              "      <td>coronavirus origin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>1</td>\n",
              "      <td>145307</td>\n",
              "      <td>vr7vm64u</td>\n",
              "      <td>999</td>\n",
              "      <td>1.472311</td>\n",
              "      <td>coronavirus origin</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    qid   docid     docno  rank     score               query\n",
              "0     1  175892  zy8qjaai     0  7.080599  coronavirus origin\n",
              "1     1   82224  8ccl9aui     1  6.775667  coronavirus origin\n",
              "2     1  135326  ne5r4d4b     2  6.683114  coronavirus origin\n",
              "3     1   93245  hmvo5b0q     3  6.507303  coronavirus origin\n",
              "4     1   84953  ax6v6ham     4  6.483723  coronavirus origin\n",
              "..   ..     ...       ...   ...       ...                 ...\n",
              "995   1  136214  ygnxmcl1   995  1.640752  coronavirus origin\n",
              "996   1   91270  853ipgea   996  1.634118  coronavirus origin\n",
              "997   1  146556  oshov14d   997  1.634118  coronavirus origin\n",
              "998   1   32462  xtfjw1ag   998  1.592462  coronavirus origin\n",
              "999   1  145307  vr7vm64u   999  1.472311  coronavirus origin\n",
              "\n",
              "[1000 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1yCXIB5w1Qb"
      },
      "source": [
        "There many other PyTerrier operators and please see examples in the [PyTerrier documentation on operators](https://pyterrier.readthedocs.io/en/latest/operators.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaYavGvnxDk5"
      },
      "source": [
        "## Task 1: Pipeline Construction (15 ponts)\n",
        "\n",
        "Create a ranker that performs the following:\n",
        " - obtains the top 10 highest scoring documents by term frequency (`wmodel=\"Tf\"`)\n",
        " - obtains the top 10 highest scoring documents by TF.IDF (`wmodel=\"TF_IDF\"`)\n",
        " - reranks only those documents found in BOTH of the previous retrieval settings using BM25.\n",
        "\n",
        "How many documents are retrieved by this full pipeline for the query `\"chemical\"`.\n",
        "> If you obtain the correct solution, the document with docno `\"37771\"` should have a score of $12.426309\t$ for query `\"chemical\"`.\n",
        "\n",
        "Hints:\n",
        " - choose carefully your [PyTerrier operators](https://pyterrier.readthedocs.io/en/latest/operators.html)\n",
        " - you should not need to perform any Pandas dataframe operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnsRdT4WvspD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "213c03b0-8c9f-4064-e623-6d59ce92d272"
      },
      "source": [
        "tf = pt.BatchRetrieve(index, wmodel=\"Tf\")\n",
        "tf_idf = pt.BatchRetrieve(index, wmodel=\"TF_IDF\")\n",
        "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
        "pipeline = ((tf % 10) & (tf_idf % 10)) >> bm25\n",
        "pipeline(\"chemical\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyterrier/transformer.py:544: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
            "  res = self.transformer.transform(topics_and_res)\n",
            "/usr/local/lib/python3.7/dist-packages/pyterrier/transformer.py:544: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
            "  res = self.transformer.transform(topics_and_res)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>docid</th>\n",
              "      <th>docno</th>\n",
              "      <th>rank</th>\n",
              "      <th>score</th>\n",
              "      <th>query</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>37771</td>\n",
              "      <td>jn5qi1jb</td>\n",
              "      <td>0</td>\n",
              "      <td>12.426309</td>\n",
              "      <td>chemical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>134305</td>\n",
              "      <td>0smev8vt</td>\n",
              "      <td>1</td>\n",
              "      <td>12.292890</td>\n",
              "      <td>chemical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>142104</td>\n",
              "      <td>77c9ohxj</td>\n",
              "      <td>2</td>\n",
              "      <td>12.226076</td>\n",
              "      <td>chemical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>56631</td>\n",
              "      <td>sps45fj5</td>\n",
              "      <td>3</td>\n",
              "      <td>11.642770</td>\n",
              "      <td>chemical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2524</td>\n",
              "      <td>ifebw24e</td>\n",
              "      <td>4</td>\n",
              "      <td>11.439890</td>\n",
              "      <td>chemical</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  qid   docid     docno  rank      score     query\n",
              "0   1   37771  jn5qi1jb     0  12.426309  chemical\n",
              "1   1  134305  0smev8vt     1  12.292890  chemical\n",
              "2   1  142104  77c9ohxj     2  12.226076  chemical\n",
              "3   1   56631  sps45fj5     3  11.642770  chemical\n",
              "4   1    2524  ifebw24e     4  11.439890  chemical"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g8V7Zzpy3g1"
      },
      "source": [
        "## Developing more complex transformers pipelines\n",
        "\n",
        "PyTerrier has a number of useful transformers that we can use to create complex retrieval pipelines. For composing pipelines, let's first define a bit of notation:\n",
        " - $Q$: a set of queries\n",
        " - $D$: a set of documents\n",
        " - $R$: a set of retrieved documents for a set of queries\n",
        "\n",
        "In our setting, we'll use three transformers:\n",
        " - `pt.BatchRetrieve(index, wmodel=\"BM25\")` - input $Q$ or $R$ (retrieval or reranking), output $R$\n",
        " - `pt.rewrite.SDM()` (sequential dependence proximity model) - input $Q$, output $Q$. \n",
        " - `pt.rewrite.Bo1QueryExpansion(index)` - input $R$, output $Q$.\n",
        "\n",
        "Note that now, we're using BM25 instead of TF-IDF to retrieve documents.\n",
        "\n",
        "Transformers like `SDM` are performing query augmentation. Here, `SDM` is reweighting terms using a Dirichlet language model like we talked about in class. However, many query rewrites a possible! For example, we could use WordNet to expand the query with synonyms or even define our own. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nJHxh7A2dPP"
      },
      "source": [
        "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
        "sdm = pt.rewrite.SDM()\n",
        "qe = pt.rewrite.Bo1QueryExpansion(index)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDQj9SdXGC5u"
      },
      "source": [
        "Let's see how `sdm` applies to a given query. This generates a query in an [Indri-like query language](https://www.lemurproject.org/lemur/IndriQueryLanguage.php) that Terrier (cf. `pt.BatchRetrieve()`) can understand.\n",
        " - `#combine()` - is used for weighting sub-expressions\n",
        " - `#1() - matches as a phrase, i.e. how many times do the constituent words exactly match as a phrase\n",
        " - `#uw8()` and `#uw12()` look for how many times the constituent words appear in unordered windows of 8 or 12 tokens.\n",
        " - finally, the weighting model is overridden for these query terms.\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ma09TN4XGC5u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "11f0bf08-11c5-4480-f2a8-0979760414a8"
      },
      "source": [
        "sdm.search(\"chemical reactions\").iloc[0][\"query\"]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'chemical reactions #combine:0=0.1:wmodel=org.terrier.matching.models.dependence.pBiL(#1(chemical reactions)) #combine:0=0.1:wmodel=org.terrier.matching.models.dependence.pBiL(#uw8(chemical reactions)) #combine:0=0.1:wmodel=org.terrier.matching.models.dependence.pBiL(#uw12(chemical reactions))'"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVmde7NpJdTT"
      },
      "source": [
        "## Task 2.1: Creating Experiments to test Pipelines (3 points)\n",
        "\n",
        "Which kinds of rankers will perform better? We can answer this by creating an [Experiment](https://pyterrier.readthedocs.io/en/latest/experiments.html) that will compare sequential dependence model and Bo1 query expansion on TREC CORD19 with the BM25 baseline. We used Experiments in Part 1, so we'll expand this idea again here to test out different pipelines.\n",
        "\n",
        "**Your Task:** You will need to construct appropriate pipelines to compare each approach by considering the input and output datatypes of the `bm25`, `sdm` and `qe`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TF24TZSb3bOo"
      },
      "source": [
        "topics = cord19.get_topics(variant='title')\n",
        "qrels = cord19.get_qrels()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqXox-g-JpUd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "9922958f-bb85-46f1-fc36-124aa84f8b7f"
      },
      "source": [
        "pipelineSDM = sdm >> bm25\n",
        "pipelinQE = bm25 >> qe >> bm25\n",
        "pt.Experiment(\n",
        "    [bm25, pipelineSDM, pipelinQE],\n",
        "    cord19.get_topics(variant='title'),\n",
        "    cord19.get_qrels(),\n",
        "    names=[\"BM25\", \"BM25+SDM\", \"BM25+QE\"],\n",
        "    eval_metrics=[\"map\", \"recip_rank\", \"ndcg\", \"ndcg_cut_5\", \"ndcg_cut_10\", \"P_5\", \"P_10\"])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>map</th>\n",
              "      <th>recip_rank</th>\n",
              "      <th>ndcg</th>\n",
              "      <th>ndcg_cut_5</th>\n",
              "      <th>ndcg_cut_10</th>\n",
              "      <th>P_5</th>\n",
              "      <th>P_10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BM25</td>\n",
              "      <td>0.181478</td>\n",
              "      <td>0.808759</td>\n",
              "      <td>0.373328</td>\n",
              "      <td>0.611724</td>\n",
              "      <td>0.583665</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BM25+SDM</td>\n",
              "      <td>0.181982</td>\n",
              "      <td>0.807438</td>\n",
              "      <td>0.373439</td>\n",
              "      <td>0.613116</td>\n",
              "      <td>0.586512</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BM25+QE</td>\n",
              "      <td>0.190398</td>\n",
              "      <td>0.814247</td>\n",
              "      <td>0.388397</td>\n",
              "      <td>0.619323</td>\n",
              "      <td>0.580906</td>\n",
              "      <td>0.696</td>\n",
              "      <td>0.638</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       name       map  recip_rank  ...  ndcg_cut_10    P_5   P_10\n",
              "0      BM25  0.181478    0.808759  ...     0.583665  0.700  0.652\n",
              "1  BM25+SDM  0.181982    0.807438  ...     0.586512  0.700  0.656\n",
              "2   BM25+QE  0.190398    0.814247  ...     0.580906  0.696  0.638\n",
              "\n",
              "[3 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-2Dvg27GC5w"
      },
      "source": [
        "### Task 2.2:  Reflection (2 points)\n",
        "\n",
        "Which approaches result in significant increases in NDCG and MAP? Is NDCG@10 also improved? Write 2-3 sentences why you think this is the case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z7g8Vz7GC5x"
      },
      "source": [
        "The Bo1 query expansion results in significant increases in MAP and NDCG, while the sequential dependence model only slightly improves MAP and NDCG.<br/>\n",
        "However, the Bo1 query expansion does not improves NDCG@10, while the sequential dependence model improves it a little."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_-D5O1gGC5x"
      },
      "source": [
        "The Bo1 query expansion model rewrite the query based on the occurences of terms in the feedback documents provided for each query. Therefore, this rewrite is done based on the statistics of all documents, which improves a lot in overall performance but performs worse in the first few retrieved documents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aJrYP1TSLwY"
      },
      "source": [
        "# Learning to Rank\n",
        "\n",
        "Now that we have some idea how to build pipelines in PyTerrier, we'll continue our exploration by constructing and evaluating Learning to Rank pipelines."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSi3svV24mCs"
      },
      "source": [
        "Learning to rank is fundamentally a machine learning approach to IR. To work, we'll need to create _training data_ to learn our ranking model. We'll also want development (\"dev\") data to evaluate hyperparameters and test data to see how well it works. Our dataset doesn't by itself already have the data split into train, dev, and test, so we'll first need to do that.\n",
        "\n",
        "TREC Covid only has 50 topics, which isn't a lot for training in general. However, for a homework, 50 is sufficient to show you how it works. In this case, we'll split this 30 for training (60%), 5 for validation (10%), and 15 for evaluation (30%). In your projects, you'll want to test for statistical significance (i.e., is the improvement better than what could be expected by chance?) so we will also examine statistical significance, though we have limited data (15 topics) to do this with.\n",
        "\n",
        "When training our model, we will only re-rank the top 500 documents for each query, which is hopefully sufficient data for learning to rank. We don't set the model to rerank _all_ documents (though you can try this!) since it causes us to have to train the Learning to Rank model on all data and is often very slow in practice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INvVKQz6K7SB"
      },
      "source": [
        "RANK_CUTOFF = 10\n",
        "SEED=42\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "tr_va_topics, test_topics = train_test_split(topics, test_size=15, random_state=SEED)\n",
        "train_topics, valid_topics =  train_test_split(tr_va_topics, test_size=5, random_state=SEED)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vftc_y-65VfA"
      },
      "source": [
        "## Defining a Feature Set for Learning to Rank\n",
        "\n",
        "Learning to Rank requires that we define which features to use in determining a ranking. We can use scores like BM25 but it's common to try adding more complex features that take advantage of what you, the IR practitioner, knows about the data or features that would be useful.\n",
        "\n",
        "For this part, we'll start with 7 features. PyTerrier provides [extensive support](https://pyterrier.readthedocs.io/en/latest/ltr.html#) for how to define features and calculate them for Learning to Rank. We recommend reading that documentation as you start to go over the code below. Note that several of these features will use more than just the text to compute relevance!\n",
        "\n",
        "1.   the BM25 abstract score;\n",
        "2.   sequential dependence model, scored by BM25;\n",
        "3.   does the abstract contain 'coronavirus covid', scored by BM25;\n",
        "4.   the BM25 score on the title (even though we didn't index it earlier!);\n",
        "5.   was the paper released/published in 2020? Recent papers were more useful for this task;\n",
        "6.   does the paper have a DOI, i.e. is it a formal publication?\n",
        "7.   the coordinate match score for the query--i.e. how many query terms appear in the abstract.\n",
        "\n",
        "Several of these feature require additional metadata `[\"title\", \"date\", \"doi\"]`, which is present in the TREC covid dataset. Fortunately, we can obtain this metadata after indexing using `pt.text.get_text(cord19, [\"title\", \"date\", \"doi\"])` to retrieve these extra metadata columns from the original data.\n",
        "\n",
        "There is a lot going on in this code block, but it's useful to think of this as _another_ example of operator overloading in PyTerrier. Here, we're combining features using the `**` operator, which is the [feature union](https://pyterrier.readthedocs.io/en/latest/ltr.html#calculating-features) operator in PyTerrier. \n",
        "\n",
        "The output of our feature union is the `ltr_feats1` object which is itself a transformer we can use to start ranking."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYgwwrsPTGP1"
      },
      "source": [
        "ltr_feats1 = (bm25 % RANK_CUTOFF) >> pt.text.get_text(cord19, [\"title\", \"date\", \"doi\"]) >> (\n",
        "    pt.transformer.IdentityTransformer()\n",
        "    ** # sequential dependence\n",
        "    (sdm >> bm25)\n",
        "    ** # score of text for query 'coronavirus covid'\n",
        "    (pt.apply.query(lambda row: 'coronavirus covid') >> bm25)\n",
        "    ** # score of title (not originally indexed)\n",
        "    (pt.text.scorer(body_attr=\"title\", takes='docs', wmodel='BM25') ) \n",
        "    ** # date 2020\n",
        "    (pt.apply.doc_score(lambda row: int(\"2020\" in row[\"date\"])))\n",
        "    ** # has doi\n",
        "    (pt.apply.doc_score(lambda row: int( row[\"doi\"] is not None and len(row[\"doi\"]) > 0) ))\n",
        "    ** # abstract coordinate match\n",
        "    pt.BatchRetrieve(index, wmodel=\"CoordinateMatch\")\n",
        ")\n",
        "\n",
        "# for reference, lets record the feature names here too\n",
        "fnames=[\"BM25\", \"SDM\", 'coronavirus covid', 'title', \"2020\", \"hasDoi\", \"CoordinateMatch\"]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nu3M9ujw6trC"
      },
      "source": [
        "To get a sense of what this process is doing, let's look at the output for the query \"coronavirus origin\". We can see that we now have extra document metadata columns `[\"title\", \"date\", \"doi\"]`, as well as the `\"features\"` column, which is what we'll use for learning. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 566
        },
        "id": "OMG9kK9AUWI4",
        "outputId": "aa8a4bf0-dca5-42ff-b678-5b053cf709e5"
      },
      "source": [
        "ltr_feats1.search(\"coronovirus origin\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "08:54:15.742 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>docid</th>\n",
              "      <th>docno</th>\n",
              "      <th>rank</th>\n",
              "      <th>score</th>\n",
              "      <th>query</th>\n",
              "      <th>title</th>\n",
              "      <th>date</th>\n",
              "      <th>doi</th>\n",
              "      <th>features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>188321</td>\n",
              "      <td>8bn74f2z</td>\n",
              "      <td>0</td>\n",
              "      <td>20.541477</td>\n",
              "      <td>coronovirus origin</td>\n",
              "      <td>Reply to Comments on 'Co‐infection of SARS‐CoV...</td>\n",
              "      <td>2020-04-08</td>\n",
              "      <td>10.1002/jmv.25838</td>\n",
              "      <td>[20.541476673741375, 20.541476673741375, 2.899...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>93090</td>\n",
              "      <td>ciqs6l7e</td>\n",
              "      <td>1</td>\n",
              "      <td>19.859401</td>\n",
              "      <td>coronovirus origin</td>\n",
              "      <td>The spread of the COVID-19 coronavirus: Health...</td>\n",
              "      <td>2020</td>\n",
              "      <td></td>\n",
              "      <td>[19.859401180444888, 19.859401180444888, 2.803...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>93091</td>\n",
              "      <td>qe9w4qbu</td>\n",
              "      <td>2</td>\n",
              "      <td>19.859401</td>\n",
              "      <td>coronovirus origin</td>\n",
              "      <td>The spread of the COVID-19 coronavirus: Health...</td>\n",
              "      <td>2020</td>\n",
              "      <td></td>\n",
              "      <td>[19.859401180444888, 19.859401180444888, 2.803...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>152453</td>\n",
              "      <td>egzztatj</td>\n",
              "      <td>3</td>\n",
              "      <td>19.459604</td>\n",
              "      <td>coronovirus origin</td>\n",
              "      <td>The spread of the COVID‐19 coronavirus: Health...</td>\n",
              "      <td>2020-03-17</td>\n",
              "      <td>10.15252/embr.202050334</td>\n",
              "      <td>[19.459604473560834, 19.459604473560834, 2.747...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>105298</td>\n",
              "      <td>9ci1u50r</td>\n",
              "      <td>4</td>\n",
              "      <td>18.009391</td>\n",
              "      <td>coronovirus origin</td>\n",
              "      <td>Placental Pathology in Covid-19 Positive Mothe...</td>\n",
              "      <td>2020</td>\n",
              "      <td></td>\n",
              "      <td>[18.009390548413062, 18.009390548413062, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>175511</td>\n",
              "      <td>kdo2hir8</td>\n",
              "      <td>5</td>\n",
              "      <td>18.009391</td>\n",
              "      <td>coronovirus origin</td>\n",
              "      <td>Placental Pathology in Covid-19 Positive Mothe...</td>\n",
              "      <td>2020-05-12</td>\n",
              "      <td>10.1177/1093526620925569</td>\n",
              "      <td>[18.009390548413062, 18.009390548413062, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>97984</td>\n",
              "      <td>76laky91</td>\n",
              "      <td>6</td>\n",
              "      <td>16.673852</td>\n",
              "      <td>coronovirus origin</td>\n",
              "      <td>Cross-species transmission of the newly identi...</td>\n",
              "      <td>2020</td>\n",
              "      <td></td>\n",
              "      <td>[16.67385232414447, 16.67385232414447, 3.37300...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>97985</td>\n",
              "      <td>niytf3wo</td>\n",
              "      <td>7</td>\n",
              "      <td>16.673852</td>\n",
              "      <td>coronovirus origin</td>\n",
              "      <td>Cross-species transmission of the newly identi...</td>\n",
              "      <td>2020</td>\n",
              "      <td></td>\n",
              "      <td>[16.67385232414447, 16.67385232414447, 3.37300...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>97986</td>\n",
              "      <td>262bcl7h</td>\n",
              "      <td>8</td>\n",
              "      <td>16.673852</td>\n",
              "      <td>coronovirus origin</td>\n",
              "      <td>Cross-species transmission of the newly identi...</td>\n",
              "      <td>2020</td>\n",
              "      <td></td>\n",
              "      <td>[16.67385232414447, 16.67385232414447, 3.37300...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>97987</td>\n",
              "      <td>nip1ax1x</td>\n",
              "      <td>9</td>\n",
              "      <td>16.673852</td>\n",
              "      <td>coronovirus origin</td>\n",
              "      <td>Cross-species transmission of the newly identi...</td>\n",
              "      <td>2020</td>\n",
              "      <td></td>\n",
              "      <td>[16.67385232414447, 16.67385232414447, 3.37300...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  qid  ...                                           features\n",
              "0   1  ...  [20.541476673741375, 20.541476673741375, 2.899...\n",
              "1   1  ...  [19.859401180444888, 19.859401180444888, 2.803...\n",
              "2   1  ...  [19.859401180444888, 19.859401180444888, 2.803...\n",
              "3   1  ...  [19.459604473560834, 19.459604473560834, 2.747...\n",
              "4   1  ...  [18.009390548413062, 18.009390548413062, 0.0, ...\n",
              "5   1  ...  [18.009390548413062, 18.009390548413062, 0.0, ...\n",
              "6   1  ...  [16.67385232414447, 16.67385232414447, 3.37300...\n",
              "7   1  ...  [16.67385232414447, 16.67385232414447, 3.37300...\n",
              "8   1  ...  [16.67385232414447, 16.67385232414447, 3.37300...\n",
              "9   1  ...  [16.67385232414447, 16.67385232414447, 3.37300...\n",
              "\n",
              "[10 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vQNbSSgJCmC"
      },
      "source": [
        "We can also look at the raw feature values themselves too. Here, we'll look at the features for the first document. Note that the BM25 in the \"score\" column above is also the first value in the feature array (20.54), because we used an identity transformer, which returns the same value as its input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzVDLL8pI_gR",
        "outputId": "711650df-e73f-4b83-c18b-55d5c4bc7fd1"
      },
      "source": [
        "ltr_feats1.search(\"coronovirus origin\").iloc[0][\"features\"]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "08:54:16.324 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([20.54147667, 20.54147667,  2.89976767,  0.        ,  1.        ,\n",
              "        1.        ,  1.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Od8P-N4E7QTk"
      },
      "source": [
        "## Actually Doing the Learning for Learning to Rank\n",
        "\n",
        "In class, we talked about three types of Learning to rank: pointwise, pairwise, and listwise. Here, we'll train a few models for two of these types, listwise and pointwise. \n",
        "\n",
        " - coordinate ascent from FastRank, a listwise linear technique\n",
        " - random forests from `scikit-learn`, a pointwise regression tree technique\n",
        " - LambdaMART from LightGBM, a listwise regression tree technique\n",
        "\n",
        "We can use the same feature pipeline, `ltr_feats1`, with all three.  To train the ranker, we compose it (`>>`) with the learned model. We use `pt.ltr.apply_learned_model()` which knows how to deal with different learners.\n",
        "\n",
        "The full pipeline is then fitted (learned) using `.fit()`, specifying the training topics and qrels, much like how we train models with Scikit-Learn. Importantly, the preceding stages of the pipeline (retrieval and feature calculation) are applied to the training topics in order to obtain the results, which are then passed to the learning to rank technique. LightGBM has early stopping enabled, which uses a validation topics set--similarly the validation topics are transformed into validation results.\n",
        "\n",
        "Finally, `%time` is notebook \"magic command\" specific to Juypyter which displays how long learning takes for each technique. Learning for each technique takes under 30 seconds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFPZ39eSYIXV",
        "outputId": "0dec5980-576f-4df8-890a-616378a9ccad"
      },
      "source": [
        "import fastrank\n",
        "\n",
        "train_request = fastrank.TrainRequest.coordinate_ascent()\n",
        "\n",
        "params = train_request.params\n",
        "params.init_random = True\n",
        "params.normalize = True\n",
        "params.seed = 1234567\n",
        "\n",
        "ca_pipe = ltr_feats1 >> pt.ltr.apply_learned_model(train_request, form='fastrank')\n",
        "\n",
        "%time ca_pipe.fit(train_topics, cord19.get_qrels())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "08:54:21.498 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyterrier/transformer.py:760: UserWarning: Got number of results different expected from <pyterrier.batchretrieve.TextScorer object at 0x7f690c3d2fd0>, expected 300 received 304, feature scores for any missing documents be 0, extraneous documents will be removed\n",
            "  warn(\"Got number of results different expected from %s, expected %d received %d, feature scores for any missing documents be 0, extraneous documents will be removed\" % (repr(m), num_results, len(res)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 46s, sys: 656 ms, total: 1min 47s\n",
            "Wall time: 59.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJKyJqhPGC51"
      },
      "source": [
        "Now, let's try learning a different pointwise model to estimate relevance scores using a Random Forest model from Scikit-Learn. This is a good example of how we can use off-the-shelf regression models in PyTerrier to perform learning to rank."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0SpZ13wUagq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7deda4f-ec8a-45bc-eab3-b85c6e9d80e2"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators=400, verbose=1, random_state=SEED, n_jobs=2)\n",
        "\n",
        "rf_pipe = ltr_feats1 >> pt.ltr.apply_learned_model(rf)\n",
        "\n",
        "%time rf_pipe.fit(train_topics, cord19.get_qrels())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "08:55:20.143 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyterrier/transformer.py:760: UserWarning: Got number of results different expected from <pyterrier.batchretrieve.TextScorer object at 0x7f690c3d2fd0>, expected 300 received 304, feature scores for any missing documents be 0, extraneous documents will be removed\n",
            "  warn(\"Got number of results different expected from %s, expected %d received %d, feature scores for any missing documents be 0, extraneous documents will be removed\" % (repr(m), num_results, len(res)))\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.8s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    3.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 20.8 s, sys: 316 ms, total: 21.1 s\n",
            "Wall time: 13.5 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    7.3s finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndUtx9D5GC52"
      },
      "source": [
        "Finally, let's use a list-wise approach, which typically performs best among the three types of Learning to Rank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0jb1jw_VdWU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca7f0467-7513-487d-97b4-5e01400bcb7e"
      },
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "# this configures LightGBM as LambdaMART\n",
        "lmart_l = lgb.LGBMRanker(\n",
        "    task=\"train\",\n",
        "    silent=False,\n",
        "    min_data_in_leaf=1,\n",
        "    min_sum_hessian_in_leaf=1,\n",
        "    max_bin=255,\n",
        "    num_leaves=31,\n",
        "    objective=\"lambdarank\",\n",
        "    metric=\"ndcg\",\n",
        "    ndcg_eval_at=[10],\n",
        "    ndcg_at=[10],\n",
        "    eval_at=[10],\n",
        "    learning_rate= .1,\n",
        "    importance_type=\"gain\",\n",
        "    num_iterations=100,\n",
        "    early_stopping_rounds=5\n",
        ")\n",
        "\n",
        "lmart_x_pipe = ltr_feats1 >> pt.ltr.apply_learned_model(lmart_l, form=\"ltr\", fit_kwargs={'eval_at':[10]})\n",
        "\n",
        "%time lmart_x_pipe.fit(train_topics, cord19.get_qrels(), valid_topics, cord19.get_qrels())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "08:55:34.447 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyterrier/transformer.py:760: UserWarning: Got number of results different expected from <pyterrier.batchretrieve.TextScorer object at 0x7f690c3d2fd0>, expected 300 received 304, feature scores for any missing documents be 0, extraneous documents will be removed\n",
            "  warn(\"Got number of results different expected from %s, expected %d received %d, feature scores for any missing documents be 0, extraneous documents will be removed\" % (repr(m), num_results, len(res)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "08:55:37.249 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyterrier/transformer.py:760: UserWarning: Got number of results different expected from <pyterrier.batchretrieve.TextScorer object at 0x7f690c3d2fd0>, expected 50 received 54, feature scores for any missing documents be 0, extraneous documents will be removed\n",
            "  warn(\"Got number of results different expected from %s, expected %d received %d, feature scores for any missing documents be 0, extraneous documents will be removed\" % (repr(m), num_results, len(res)))\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:156: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] early_stopping_round is set=5, early_stopping_rounds=5 will be ignored. Current value: early_stopping_round=5\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001703 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 351\n",
            "[LightGBM] [Info] Number of data points in the train set: 65832, number of used features: 7\n",
            "[LightGBM] [Warning] early_stopping_round is set=5, early_stopping_rounds=5 will be ignored. Current value: early_stopping_round=5\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[1]\tvalid_0's ndcg@10: 0.852789\n",
            "Training until validation scores don't improve for 5 rounds\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[2]\tvalid_0's ndcg@10: 0.852789\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[3]\tvalid_0's ndcg@10: 0.852789\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[4]\tvalid_0's ndcg@10: 0.852789\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[5]\tvalid_0's ndcg@10: 0.852789\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[6]\tvalid_0's ndcg@10: 0.852789\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's ndcg@10: 0.852789\n",
            "CPU times: user 11.5 s, sys: 306 ms, total: 11.8 s\n",
            "Wall time: 10.3 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7rNqB7sBKFB"
      },
      "source": [
        "## Evaluating all the solutions \n",
        "\n",
        "We've fit the three Learning to Rank models so we can now use them to predict relevance scores for the held-out 15 topics (queries) in our test set. Note that if we wanted to do any tuning (e.g., pick the number of leaves in our `RandomForestRegressor`, we could run this evaluation on our held-out _dev_ set and pick the hyperparameters that produced best performance on it).\n",
        "\n",
        "### Task 3: Create an experiment to compare (5 points)\n",
        "\n",
        "Create a new `Experiment` to compare our three solutions and BM25 at the `RANK_CUTOFF` (four models in total). Report MAP, NDCG, and NDCG@10 measures and one new measure: mean response time (`\"mrt\"`), which will tell us how fast the models are able to score documents--something important if we're going to use them in the real world!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0EhTwejVqev",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "a9bd18e3-d995-4287-9ed0-0529688bada5"
      },
      "source": [
        "pt.Experiment(\n",
        "    [bm25 % RANK_CUTOFF, ca_pipe, rf_pipe, lmart_x_pipe], \n",
        "    test_topics, \n",
        "    qrels, \n",
        "    names=[\"BM25\",  \"BM25+CA\", \"BM25+RF\", \"BM25+LMart\"], \n",
        "    baseline=0, \n",
        "    eval_metrics=[\"map\", \"ndcg\", \"ndcg_cut_10\", \"mrt\"])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "08:55:42.897 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n",
            "08:55:45.498 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "08:55:48.273 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>map</th>\n",
              "      <th>ndcg</th>\n",
              "      <th>ndcg_cut_10</th>\n",
              "      <th>mrt</th>\n",
              "      <th>map +</th>\n",
              "      <th>map -</th>\n",
              "      <th>map p-value</th>\n",
              "      <th>ndcg +</th>\n",
              "      <th>ndcg -</th>\n",
              "      <th>ndcg p-value</th>\n",
              "      <th>ndcg_cut_10 +</th>\n",
              "      <th>ndcg_cut_10 -</th>\n",
              "      <th>ndcg_cut_10 p-value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BM25</td>\n",
              "      <td>0.010480</td>\n",
              "      <td>0.043844</td>\n",
              "      <td>0.537236</td>\n",
              "      <td>49.081292</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BM25+CA</td>\n",
              "      <td>0.012251</td>\n",
              "      <td>0.049097</td>\n",
              "      <td>0.578831</td>\n",
              "      <td>165.989755</td>\n",
              "      <td>9.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.035093</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.069393</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.128795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BM25+RF</td>\n",
              "      <td>0.011271</td>\n",
              "      <td>0.045830</td>\n",
              "      <td>0.551404</td>\n",
              "      <td>187.197598</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.216817</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.233364</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.420787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BM25+LMart</td>\n",
              "      <td>0.009926</td>\n",
              "      <td>0.042458</td>\n",
              "      <td>0.528034</td>\n",
              "      <td>151.153882</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.322366</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.503059</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.604548</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         name       map  ...  ndcg_cut_10 -  ndcg_cut_10 p-value\n",
              "0        BM25  0.010480  ...            NaN                  NaN\n",
              "1     BM25+CA  0.012251  ...            4.0             0.128795\n",
              "2     BM25+RF  0.011271  ...            4.0             0.420787\n",
              "3  BM25+LMart  0.009926  ...            7.0             0.604548\n",
              "\n",
              "[4 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmGe5rniC_Pn"
      },
      "source": [
        "Thats really interesting – all three learned models could improve NDCG@10 over BM25, but the coordinate ascent model improved the most (significantly so on all three metrics, but again on only 15 queries). Coordinate Ascent improved upto 10 queries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ov0JjWGEbrT"
      },
      "source": [
        "## Analysis: What Features Matter?\n",
        "\n",
        "Since we're _learning_ a ranking model, we can inspect that model to see what information it's using. One option for inspecting the model is to evaluate the performance of each feature independently to see how much it contributes to the eventual relevance. To examine each feature, we will create separate a separate model from each feature in our feature pipeline (`ltr_feats1`) by using `pt.ltr.feature_to_score(i)` with a particular feature number $i$. In essence, this will only score the relevance using a single feature's values, even though we've already calculated all of them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nCb9U7uvszV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "b6e91db2-2a67-4495-d11a-db46301379b0"
      },
      "source": [
        "pt.Experiment(\n",
        "    [ltr_feats1 >> pt.ltr.feature_to_score(i) for i in range(len(fnames))],\n",
        "    test_topics,\n",
        "    qrels, \n",
        "    names=fnames,\n",
        "    eval_metrics=[\"map\", \"ndcg\", \"ndcg_cut_10\", \"num_rel_ret\"])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "08:55:50.616 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n",
            "08:55:52.998 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n",
            "08:55:55.220 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n",
            "08:55:57.572 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n",
            "08:55:59.882 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n",
            "08:56:02.140 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n",
            "08:56:04.540 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>map</th>\n",
              "      <th>ndcg</th>\n",
              "      <th>ndcg_cut_10</th>\n",
              "      <th>num_rel_ret</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BM25</td>\n",
              "      <td>0.010480</td>\n",
              "      <td>0.043844</td>\n",
              "      <td>0.537236</td>\n",
              "      <td>95.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SDM</td>\n",
              "      <td>0.010429</td>\n",
              "      <td>0.043568</td>\n",
              "      <td>0.535770</td>\n",
              "      <td>95.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>coronavirus covid</td>\n",
              "      <td>0.011637</td>\n",
              "      <td>0.046777</td>\n",
              "      <td>0.562223</td>\n",
              "      <td>95.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>title</td>\n",
              "      <td>0.011799</td>\n",
              "      <td>0.047354</td>\n",
              "      <td>0.567363</td>\n",
              "      <td>95.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020</td>\n",
              "      <td>0.011064</td>\n",
              "      <td>0.045604</td>\n",
              "      <td>0.555846</td>\n",
              "      <td>95.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>hasDoi</td>\n",
              "      <td>0.009928</td>\n",
              "      <td>0.042970</td>\n",
              "      <td>0.531974</td>\n",
              "      <td>95.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>CoordinateMatch</td>\n",
              "      <td>0.010742</td>\n",
              "      <td>0.044333</td>\n",
              "      <td>0.540893</td>\n",
              "      <td>95.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                name       map      ndcg  ndcg_cut_10  num_rel_ret\n",
              "0               BM25  0.010480  0.043844     0.537236         95.0\n",
              "1                SDM  0.010429  0.043568     0.535770         95.0\n",
              "2  coronavirus covid  0.011637  0.046777     0.562223         95.0\n",
              "3              title  0.011799  0.047354     0.567363         95.0\n",
              "4               2020  0.011064  0.045604     0.555846         95.0\n",
              "5             hasDoi  0.009928  0.042970     0.531974         95.0\n",
              "6    CoordinateMatch  0.010742  0.044333     0.540893         95.0"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU7YYKFSFeke"
      },
      "source": [
        "### Inspecting the models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjaWBEo8HA20"
      },
      "source": [
        "To get a sense of feature importance, we can also analyze the learned models themselves using their internal feature weights in the Scikit-Learn models. Here, we'll plot the feature importances in a few ways. For the coordinate ascent model, we plot the feature weights (note the log-scale y-axis); while for the regression-tree based techniques, we report the feature importance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdOP1b8Cjp44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "outputId": "be6a7f35-546c-4326-9aef-6945359c532a"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt, numpy as np\n",
        "\n",
        "fig, (ax0, ax1, ax2) = plt.subplots(1, 3, figsize=(10, 6))\n",
        "\n",
        "ax0.bar(np.arange(len(fnames)), ca_pipe[1].model.to_dict()['Linear']['weights'])\n",
        "ax0.set_xticks(np.arange(len(fnames)))\n",
        "ax0.set_xticklabels(fnames, rotation=45, ha='right')\n",
        "ax0.set_title(\"Coordinate Ascent\\n Feature Weights\")\n",
        "ax0.set_yscale('log')\n",
        "\n",
        "ax1.bar(np.arange(len(fnames)), rf.feature_importances_)\n",
        "ax1.set_xticks(np.arange(len(fnames)))\n",
        "ax1.set_xticklabels(fnames, rotation=45, ha='right')\n",
        "ax1.set_title(\"Random Forests\\n Feature Importance\")\n",
        "\n",
        "ax2.bar(np.arange(len(fnames)), lmart_l.feature_importances_)\n",
        "ax2.set_xticks(np.arange(len(fnames)))\n",
        "ax2.set_xticklabels(fnames, rotation=45, ha='right')\n",
        "ax2.set_title(\"$\\lambda$MART\\n Feature Importance\")\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HhGDiPLHO7v"
      },
      "source": [
        "## Task 4: Adding new features (15 points)\n",
        "\n",
        "We've seen how to develop Learning to Rank models and analyze features. Your task is the following:\n",
        "\n",
        "  - Define _at least_ two additional features to use in learning to rank models. These can be functions that you define or additional options from PyTerrier\n",
        "  - Include your new features in a new learning to rank pipeline using the three approaches we have above to create three new models\n",
        "  - Evaluate your new models against the old models in an Experiment\n",
        " \n",
        "**Full credit will depend on one of your new models outperforming the best of the initial three models.**\n",
        "\n",
        "You should aim to evaluate your features initially on the `dev` set, rather than the `test` set in order to avoid overfitting your features (i.e., never look at the test set until the end). You can use the feature and model inspection code to give you some idea of what the model is looking at. We also recommend looking at the data directly to think about what kinds of features might be useful"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dam4esAKGC55"
      },
      "source": [
        "ltr_feats2 = (bm25 % RANK_CUTOFF) >> pt.text.get_text(cord19, [\"title\", \"date\", \"doi\", \"abstract\"]) >> (\n",
        "    pt.transformer.IdentityTransformer()\n",
        "    ** # sequential dependence\n",
        "    (sdm >> bm25)\n",
        "    ** # score of text for query 'coronavirus covid'\n",
        "    (pt.apply.query(lambda row: 'coronavirus covid') >> bm25)\n",
        "    ** # score of title (not originally indexed)\n",
        "    (pt.text.scorer(body_attr=\"title\", takes='docs', wmodel='BM25') ) \n",
        "    ** # date 2020\n",
        "    (pt.apply.doc_score(lambda row: int(\"2020\" in row[\"date\"])))\n",
        "    ** # has doi\n",
        "    (pt.apply.doc_score(lambda row: int( row[\"doi\"] is not None and len(row[\"doi\"]) > 0) ))\n",
        "    ** # abstract coordinate match\n",
        "    pt.BatchRetrieve(index, wmodel=\"CoordinateMatch\")\n",
        "    ** # COVID-19 in title\n",
        "    (pt.apply.doc_score(lambda row: int(\"COVID-19\" in row[\"title\"] or \"Covid-19\" in row[\"title\"])))\n",
        "    ** # Bo1 Query Expansion\n",
        "    (bm25 >> qe >> bm25)\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wc-lh4myTGU3",
        "outputId": "27e9f1a3-9205-4766-954d-836571aca1c3"
      },
      "source": [
        "train_request2 = fastrank.TrainRequest.coordinate_ascent()\n",
        "\n",
        "params = train_request2.params\n",
        "params.init_random = True\n",
        "params.normalize = True\n",
        "params.seed = 1234567\n",
        "\n",
        "ca_pipe2 = ltr_feats2 >> pt.ltr.apply_learned_model(train_request2, form='fastrank')\n",
        "\n",
        "%time ca_pipe2.fit(train_topics, cord19.get_qrels())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "08:56:10.732 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyterrier/transformer.py:760: UserWarning: Got number of results different expected from ComposedPipeline(ComposedPipeline(BR(/content/terrier_trec_covid_positional_indices/data.properties,{'terrierql': 'on', 'parsecontrols': 'on', 'parseql': 'on', 'applypipeline': 'on', 'localmatching': 'on', 'filters': 'on', 'decorate': 'on', 'wmodel': 'BM25'},{'querying.processes': 'terrierql:TerrierQLParser,parsecontrols:TerrierQLToControls,parseql:TerrierQLToMatchingQueryTerms,matchopql:MatchingOpQLParser,applypipeline:ApplyTermPipeline,context_wmodel:org.terrier.python.WmodelFromContextProcess,localmatching:LocalManager$ApplyLocalMatching,qe:QueryExpansion,labels:org.terrier.learning.LabelDecorator,filters:LocalManager$PostFilterProcess,decorate:SimpleDecorateProcess', 'querying.postfilters': 'decorate:SimpleDecorate,site:SiteFilter,scope:Scope', 'querying.default.controls': 'wmodel:DPH,parsecontrols:on,parseql:on,applypipeline:on,terrierql:on,localmatching:on,filters:on,decorate:on', 'querying.allowed.controls': 'scope,qe,qemodel,start,end,site,scope,applypipeline', 'termpipelines': 'Stopwords,PorterStemmer'}), <pyterrier.rewrite.Bo1QueryExpansion object at 0x7f690e056f50>), BR(/content/terrier_trec_covid_positional_indices/data.properties,{'terrierql': 'on', 'parsecontrols': 'on', 'parseql': 'on', 'applypipeline': 'on', 'localmatching': 'on', 'filters': 'on', 'decorate': 'on', 'wmodel': 'BM25'},{'querying.processes': 'terrierql:TerrierQLParser,parsecontrols:TerrierQLToControls,parseql:TerrierQLToMatchingQueryTerms,matchopql:MatchingOpQLParser,applypipeline:ApplyTermPipeline,context_wmodel:org.terrier.python.WmodelFromContextProcess,localmatching:LocalManager$ApplyLocalMatching,qe:QueryExpansion,labels:org.terrier.learning.LabelDecorator,filters:LocalManager$PostFilterProcess,decorate:SimpleDecorateProcess', 'querying.postfilters': 'decorate:SimpleDecorate,site:SiteFilter,scope:Scope', 'querying.default.controls': 'wmodel:DPH,parsecontrols:on,parseql:on,applypipeline:on,terrierql:on,localmatching:on,filters:on,decorate:on', 'querying.allowed.controls': 'scope,qe,qemodel,start,end,site,scope,applypipeline', 'termpipelines': 'Stopwords,PorterStemmer'})), expected 300 received 30000, feature scores for any missing documents be 0, extraneous documents will be removed\n",
            "  warn(\"Got number of results different expected from %s, expected %d received %d, feature scores for any missing documents be 0, extraneous documents will be removed\" % (repr(m), num_results, len(res)))\n",
            "/usr/local/lib/python3.7/dist-packages/pyterrier/transformer.py:760: UserWarning: Got number of results different expected from <pyterrier.batchretrieve.TextScorer object at 0x7f690beaa190>, expected 300 received 304, feature scores for any missing documents be 0, extraneous documents will be removed\n",
            "  warn(\"Got number of results different expected from %s, expected %d received %d, feature scores for any missing documents be 0, extraneous documents will be removed\" % (repr(m), num_results, len(res)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1h 26min 17s, sys: 21.7 s, total: 1h 26min 39s\n",
            "Wall time: 46min 51s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vL37ON7EWJ2m",
        "outputId": "9b81ccb9-7c0f-48d9-c52b-a58012298f3a"
      },
      "source": [
        "rf2 = RandomForestRegressor(n_estimators=400, verbose=1, random_state=SEED, n_jobs=2)\n",
        "\n",
        "rf_pipe2 = ltr_feats2 >> pt.ltr.apply_learned_model(rf2)\n",
        "\n",
        "%time rf_pipe2.fit(train_topics, cord19.get_qrels())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "09:43:02.071 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyterrier/transformer.py:760: UserWarning: Got number of results different expected from ComposedPipeline(ComposedPipeline(BR(/content/terrier_trec_covid_positional_indices/data.properties,{'terrierql': 'on', 'parsecontrols': 'on', 'parseql': 'on', 'applypipeline': 'on', 'localmatching': 'on', 'filters': 'on', 'decorate': 'on', 'wmodel': 'BM25'},{'querying.processes': 'terrierql:TerrierQLParser,parsecontrols:TerrierQLToControls,parseql:TerrierQLToMatchingQueryTerms,matchopql:MatchingOpQLParser,applypipeline:ApplyTermPipeline,context_wmodel:org.terrier.python.WmodelFromContextProcess,localmatching:LocalManager$ApplyLocalMatching,qe:QueryExpansion,labels:org.terrier.learning.LabelDecorator,filters:LocalManager$PostFilterProcess,decorate:SimpleDecorateProcess', 'querying.postfilters': 'decorate:SimpleDecorate,site:SiteFilter,scope:Scope', 'querying.default.controls': 'wmodel:DPH,parsecontrols:on,parseql:on,applypipeline:on,terrierql:on,localmatching:on,filters:on,decorate:on', 'querying.allowed.controls': 'scope,qe,qemodel,start,end,site,scope,applypipeline', 'termpipelines': 'Stopwords,PorterStemmer'}), <pyterrier.rewrite.Bo1QueryExpansion object at 0x7f690e056f50>), BR(/content/terrier_trec_covid_positional_indices/data.properties,{'terrierql': 'on', 'parsecontrols': 'on', 'parseql': 'on', 'applypipeline': 'on', 'localmatching': 'on', 'filters': 'on', 'decorate': 'on', 'wmodel': 'BM25'},{'querying.processes': 'terrierql:TerrierQLParser,parsecontrols:TerrierQLToControls,parseql:TerrierQLToMatchingQueryTerms,matchopql:MatchingOpQLParser,applypipeline:ApplyTermPipeline,context_wmodel:org.terrier.python.WmodelFromContextProcess,localmatching:LocalManager$ApplyLocalMatching,qe:QueryExpansion,labels:org.terrier.learning.LabelDecorator,filters:LocalManager$PostFilterProcess,decorate:SimpleDecorateProcess', 'querying.postfilters': 'decorate:SimpleDecorate,site:SiteFilter,scope:Scope', 'querying.default.controls': 'wmodel:DPH,parsecontrols:on,parseql:on,applypipeline:on,terrierql:on,localmatching:on,filters:on,decorate:on', 'querying.allowed.controls': 'scope,qe,qemodel,start,end,site,scope,applypipeline', 'termpipelines': 'Stopwords,PorterStemmer'})), expected 300 received 30000, feature scores for any missing documents be 0, extraneous documents will be removed\n",
            "  warn(\"Got number of results different expected from %s, expected %d received %d, feature scores for any missing documents be 0, extraneous documents will be removed\" % (repr(m), num_results, len(res)))\n",
            "/usr/local/lib/python3.7/dist-packages/pyterrier/transformer.py:760: UserWarning: Got number of results different expected from <pyterrier.batchretrieve.TextScorer object at 0x7f690beaa190>, expected 300 received 304, feature scores for any missing documents be 0, extraneous documents will be removed\n",
            "  warn(\"Got number of results different expected from %s, expected %d received %d, feature scores for any missing documents be 0, extraneous documents will be removed\" % (repr(m), num_results, len(res)))\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   57.3s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:  8.2min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 17min 4s, sys: 5.14 s, total: 17min 9s\n",
            "Wall time: 9min 11s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ynvIXhwWN9n",
        "outputId": "be273982-4e38-4bf5-8b19-b69fe66e6160"
      },
      "source": [
        "# this configures LightGBM as LambdaMART\n",
        "lmart_l = lgb.LGBMRanker(\n",
        "    task=\"train\",\n",
        "    silent=False,\n",
        "    min_data_in_leaf=1,\n",
        "    min_sum_hessian_in_leaf=1,\n",
        "    max_bin=255,\n",
        "    num_leaves=31,\n",
        "    objective=\"lambdarank\",\n",
        "    metric=\"ndcg\",\n",
        "    ndcg_eval_at=[10],\n",
        "    ndcg_at=[10],\n",
        "    eval_at=[10],\n",
        "    learning_rate= .1,\n",
        "    importance_type=\"gain\",\n",
        "    num_iterations=100,\n",
        "    early_stopping_rounds=5\n",
        ")\n",
        "\n",
        "lmart_x_pipe2 = ltr_feats2 >> pt.ltr.apply_learned_model(lmart_l, form=\"ltr\", fit_kwargs={'eval_at':[10]})\n",
        "\n",
        "%time lmart_x_pipe2.fit(train_topics, cord19.get_qrels(), valid_topics, cord19.get_qrels())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "09:52:13.409 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyterrier/transformer.py:760: UserWarning: Got number of results different expected from ComposedPipeline(ComposedPipeline(BR(/content/terrier_trec_covid_positional_indices/data.properties,{'terrierql': 'on', 'parsecontrols': 'on', 'parseql': 'on', 'applypipeline': 'on', 'localmatching': 'on', 'filters': 'on', 'decorate': 'on', 'wmodel': 'BM25'},{'querying.processes': 'terrierql:TerrierQLParser,parsecontrols:TerrierQLToControls,parseql:TerrierQLToMatchingQueryTerms,matchopql:MatchingOpQLParser,applypipeline:ApplyTermPipeline,context_wmodel:org.terrier.python.WmodelFromContextProcess,localmatching:LocalManager$ApplyLocalMatching,qe:QueryExpansion,labels:org.terrier.learning.LabelDecorator,filters:LocalManager$PostFilterProcess,decorate:SimpleDecorateProcess', 'querying.postfilters': 'decorate:SimpleDecorate,site:SiteFilter,scope:Scope', 'querying.default.controls': 'wmodel:DPH,parsecontrols:on,parseql:on,applypipeline:on,terrierql:on,localmatching:on,filters:on,decorate:on', 'querying.allowed.controls': 'scope,qe,qemodel,start,end,site,scope,applypipeline', 'termpipelines': 'Stopwords,PorterStemmer'}), <pyterrier.rewrite.Bo1QueryExpansion object at 0x7f690e056f50>), BR(/content/terrier_trec_covid_positional_indices/data.properties,{'terrierql': 'on', 'parsecontrols': 'on', 'parseql': 'on', 'applypipeline': 'on', 'localmatching': 'on', 'filters': 'on', 'decorate': 'on', 'wmodel': 'BM25'},{'querying.processes': 'terrierql:TerrierQLParser,parsecontrols:TerrierQLToControls,parseql:TerrierQLToMatchingQueryTerms,matchopql:MatchingOpQLParser,applypipeline:ApplyTermPipeline,context_wmodel:org.terrier.python.WmodelFromContextProcess,localmatching:LocalManager$ApplyLocalMatching,qe:QueryExpansion,labels:org.terrier.learning.LabelDecorator,filters:LocalManager$PostFilterProcess,decorate:SimpleDecorateProcess', 'querying.postfilters': 'decorate:SimpleDecorate,site:SiteFilter,scope:Scope', 'querying.default.controls': 'wmodel:DPH,parsecontrols:on,parseql:on,applypipeline:on,terrierql:on,localmatching:on,filters:on,decorate:on', 'querying.allowed.controls': 'scope,qe,qemodel,start,end,site,scope,applypipeline', 'termpipelines': 'Stopwords,PorterStemmer'})), expected 300 received 30000, feature scores for any missing documents be 0, extraneous documents will be removed\n",
            "  warn(\"Got number of results different expected from %s, expected %d received %d, feature scores for any missing documents be 0, extraneous documents will be removed\" % (repr(m), num_results, len(res)))\n",
            "/usr/local/lib/python3.7/dist-packages/pyterrier/transformer.py:760: UserWarning: Got number of results different expected from <pyterrier.batchretrieve.TextScorer object at 0x7f690beaa190>, expected 300 received 304, feature scores for any missing documents be 0, extraneous documents will be removed\n",
            "  warn(\"Got number of results different expected from %s, expected %d received %d, feature scores for any missing documents be 0, extraneous documents will be removed\" % (repr(m), num_results, len(res)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "09:52:57.577 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyterrier/transformer.py:760: UserWarning: Got number of results different expected from ComposedPipeline(ComposedPipeline(BR(/content/terrier_trec_covid_positional_indices/data.properties,{'terrierql': 'on', 'parsecontrols': 'on', 'parseql': 'on', 'applypipeline': 'on', 'localmatching': 'on', 'filters': 'on', 'decorate': 'on', 'wmodel': 'BM25'},{'querying.processes': 'terrierql:TerrierQLParser,parsecontrols:TerrierQLToControls,parseql:TerrierQLToMatchingQueryTerms,matchopql:MatchingOpQLParser,applypipeline:ApplyTermPipeline,context_wmodel:org.terrier.python.WmodelFromContextProcess,localmatching:LocalManager$ApplyLocalMatching,qe:QueryExpansion,labels:org.terrier.learning.LabelDecorator,filters:LocalManager$PostFilterProcess,decorate:SimpleDecorateProcess', 'querying.postfilters': 'decorate:SimpleDecorate,site:SiteFilter,scope:Scope', 'querying.default.controls': 'wmodel:DPH,parsecontrols:on,parseql:on,applypipeline:on,terrierql:on,localmatching:on,filters:on,decorate:on', 'querying.allowed.controls': 'scope,qe,qemodel,start,end,site,scope,applypipeline', 'termpipelines': 'Stopwords,PorterStemmer'}), <pyterrier.rewrite.Bo1QueryExpansion object at 0x7f690e056f50>), BR(/content/terrier_trec_covid_positional_indices/data.properties,{'terrierql': 'on', 'parsecontrols': 'on', 'parseql': 'on', 'applypipeline': 'on', 'localmatching': 'on', 'filters': 'on', 'decorate': 'on', 'wmodel': 'BM25'},{'querying.processes': 'terrierql:TerrierQLParser,parsecontrols:TerrierQLToControls,parseql:TerrierQLToMatchingQueryTerms,matchopql:MatchingOpQLParser,applypipeline:ApplyTermPipeline,context_wmodel:org.terrier.python.WmodelFromContextProcess,localmatching:LocalManager$ApplyLocalMatching,qe:QueryExpansion,labels:org.terrier.learning.LabelDecorator,filters:LocalManager$PostFilterProcess,decorate:SimpleDecorateProcess', 'querying.postfilters': 'decorate:SimpleDecorate,site:SiteFilter,scope:Scope', 'querying.default.controls': 'wmodel:DPH,parsecontrols:on,parseql:on,applypipeline:on,terrierql:on,localmatching:on,filters:on,decorate:on', 'querying.allowed.controls': 'scope,qe,qemodel,start,end,site,scope,applypipeline', 'termpipelines': 'Stopwords,PorterStemmer'})), expected 50 received 5000, feature scores for any missing documents be 0, extraneous documents will be removed\n",
            "  warn(\"Got number of results different expected from %s, expected %d received %d, feature scores for any missing documents be 0, extraneous documents will be removed\" % (repr(m), num_results, len(res)))\n",
            "/usr/local/lib/python3.7/dist-packages/pyterrier/transformer.py:760: UserWarning: Got number of results different expected from <pyterrier.batchretrieve.TextScorer object at 0x7f690beaa190>, expected 50 received 54, feature scores for any missing documents be 0, extraneous documents will be removed\n",
            "  warn(\"Got number of results different expected from %s, expected %d received %d, feature scores for any missing documents be 0, extraneous documents will be removed\" % (repr(m), num_results, len(res)))\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:156: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] early_stopping_round is set=5, early_stopping_rounds=5 will be ignored. Current value: early_stopping_round=5\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068904 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 83\n",
            "[LightGBM] [Info] Number of data points in the train set: 2097448, number of used features: 9\n",
            "[LightGBM] [Warning] early_stopping_round is set=5, early_stopping_rounds=5 will be ignored. Current value: early_stopping_round=5\n",
            "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[1]\tvalid_0's ndcg@10: 0.852789\n",
            "Training until validation scores don't improve for 5 rounds\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[2]\tvalid_0's ndcg@10: 0.852789\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[3]\tvalid_0's ndcg@10: 0.852789\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[4]\tvalid_0's ndcg@10: 0.852789\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[5]\tvalid_0's ndcg@10: 0.852789\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[6]\tvalid_0's ndcg@10: 0.852789\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's ndcg@10: 0.852789\n",
            "CPU times: user 1min 50s, sys: 5.8 s, total: 1min 55s\n",
            "Wall time: 1min 48s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "EJzNxLJSXAFj",
        "outputId": "54227e52-9f84-4aaa-ec0c-e68585f85c86"
      },
      "source": [
        "pt.Experiment(\n",
        "    [bm25 % RANK_CUTOFF, ca_pipe, rf_pipe, lmart_x_pipe, ca_pipe2, rf_pipe2, lmart_x_pipe2], \n",
        "    test_topics, \n",
        "    qrels, \n",
        "    names=[\"BM25\",  \"BM25+CA\", \"BM25+RF\", \"BM25+LMart\", \"New BM25+CA\", \"New BM25+RF\", \"New BM25+LMart\"], \n",
        "    baseline=0, \n",
        "    eval_metrics=[\"map\", \"ndcg\", \"ndcg_cut_10\", \"mrt\"])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "09:54:00.790 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n",
            "09:54:02.791 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "09:54:05.441 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n",
            "09:54:07.535 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyterrier/transformer.py:760: UserWarning: Got number of results different expected from ComposedPipeline(ComposedPipeline(BR(/content/terrier_trec_covid_positional_indices/data.properties,{'terrierql': 'on', 'parsecontrols': 'on', 'parseql': 'on', 'applypipeline': 'on', 'localmatching': 'on', 'filters': 'on', 'decorate': 'on', 'wmodel': 'BM25'},{'querying.processes': 'terrierql:TerrierQLParser,parsecontrols:TerrierQLToControls,parseql:TerrierQLToMatchingQueryTerms,matchopql:MatchingOpQLParser,applypipeline:ApplyTermPipeline,context_wmodel:org.terrier.python.WmodelFromContextProcess,localmatching:LocalManager$ApplyLocalMatching,qe:QueryExpansion,labels:org.terrier.learning.LabelDecorator,filters:LocalManager$PostFilterProcess,decorate:SimpleDecorateProcess', 'querying.postfilters': 'decorate:SimpleDecorate,site:SiteFilter,scope:Scope', 'querying.default.controls': 'wmodel:DPH,parsecontrols:on,parseql:on,applypipeline:on,terrierql:on,localmatching:on,filters:on,decorate:on', 'querying.allowed.controls': 'scope,qe,qemodel,start,end,site,scope,applypipeline', 'termpipelines': 'Stopwords,PorterStemmer'}), <pyterrier.rewrite.Bo1QueryExpansion object at 0x7f690e056f50>), BR(/content/terrier_trec_covid_positional_indices/data.properties,{'terrierql': 'on', 'parsecontrols': 'on', 'parseql': 'on', 'applypipeline': 'on', 'localmatching': 'on', 'filters': 'on', 'decorate': 'on', 'wmodel': 'BM25'},{'querying.processes': 'terrierql:TerrierQLParser,parsecontrols:TerrierQLToControls,parseql:TerrierQLToMatchingQueryTerms,matchopql:MatchingOpQLParser,applypipeline:ApplyTermPipeline,context_wmodel:org.terrier.python.WmodelFromContextProcess,localmatching:LocalManager$ApplyLocalMatching,qe:QueryExpansion,labels:org.terrier.learning.LabelDecorator,filters:LocalManager$PostFilterProcess,decorate:SimpleDecorateProcess', 'querying.postfilters': 'decorate:SimpleDecorate,site:SiteFilter,scope:Scope', 'querying.default.controls': 'wmodel:DPH,parsecontrols:on,parseql:on,applypipeline:on,terrierql:on,localmatching:on,filters:on,decorate:on', 'querying.allowed.controls': 'scope,qe,qemodel,start,end,site,scope,applypipeline', 'termpipelines': 'Stopwords,PorterStemmer'})), expected 150 received 15000, feature scores for any missing documents be 0, extraneous documents will be removed\n",
            "  warn(\"Got number of results different expected from %s, expected %d received %d, feature scores for any missing documents be 0, extraneous documents will be removed\" % (repr(m), num_results, len(res)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "09:54:11.092 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyterrier/transformer.py:760: UserWarning: Got number of results different expected from ComposedPipeline(ComposedPipeline(BR(/content/terrier_trec_covid_positional_indices/data.properties,{'terrierql': 'on', 'parsecontrols': 'on', 'parseql': 'on', 'applypipeline': 'on', 'localmatching': 'on', 'filters': 'on', 'decorate': 'on', 'wmodel': 'BM25'},{'querying.processes': 'terrierql:TerrierQLParser,parsecontrols:TerrierQLToControls,parseql:TerrierQLToMatchingQueryTerms,matchopql:MatchingOpQLParser,applypipeline:ApplyTermPipeline,context_wmodel:org.terrier.python.WmodelFromContextProcess,localmatching:LocalManager$ApplyLocalMatching,qe:QueryExpansion,labels:org.terrier.learning.LabelDecorator,filters:LocalManager$PostFilterProcess,decorate:SimpleDecorateProcess', 'querying.postfilters': 'decorate:SimpleDecorate,site:SiteFilter,scope:Scope', 'querying.default.controls': 'wmodel:DPH,parsecontrols:on,parseql:on,applypipeline:on,terrierql:on,localmatching:on,filters:on,decorate:on', 'querying.allowed.controls': 'scope,qe,qemodel,start,end,site,scope,applypipeline', 'termpipelines': 'Stopwords,PorterStemmer'}), <pyterrier.rewrite.Bo1QueryExpansion object at 0x7f690e056f50>), BR(/content/terrier_trec_covid_positional_indices/data.properties,{'terrierql': 'on', 'parsecontrols': 'on', 'parseql': 'on', 'applypipeline': 'on', 'localmatching': 'on', 'filters': 'on', 'decorate': 'on', 'wmodel': 'BM25'},{'querying.processes': 'terrierql:TerrierQLParser,parsecontrols:TerrierQLToControls,parseql:TerrierQLToMatchingQueryTerms,matchopql:MatchingOpQLParser,applypipeline:ApplyTermPipeline,context_wmodel:org.terrier.python.WmodelFromContextProcess,localmatching:LocalManager$ApplyLocalMatching,qe:QueryExpansion,labels:org.terrier.learning.LabelDecorator,filters:LocalManager$PostFilterProcess,decorate:SimpleDecorateProcess', 'querying.postfilters': 'decorate:SimpleDecorate,site:SiteFilter,scope:Scope', 'querying.default.controls': 'wmodel:DPH,parsecontrols:on,parseql:on,applypipeline:on,terrierql:on,localmatching:on,filters:on,decorate:on', 'querying.allowed.controls': 'scope,qe,qemodel,start,end,site,scope,applypipeline', 'termpipelines': 'Stopwords,PorterStemmer'})), expected 150 received 15000, feature scores for any missing documents be 0, extraneous documents will be removed\n",
            "  warn(\"Got number of results different expected from %s, expected %d received %d, feature scores for any missing documents be 0, extraneous documents will be removed\" % (repr(m), num_results, len(res)))\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "09:54:14.962 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyterrier/transformer.py:760: UserWarning: Got number of results different expected from ComposedPipeline(ComposedPipeline(BR(/content/terrier_trec_covid_positional_indices/data.properties,{'terrierql': 'on', 'parsecontrols': 'on', 'parseql': 'on', 'applypipeline': 'on', 'localmatching': 'on', 'filters': 'on', 'decorate': 'on', 'wmodel': 'BM25'},{'querying.processes': 'terrierql:TerrierQLParser,parsecontrols:TerrierQLToControls,parseql:TerrierQLToMatchingQueryTerms,matchopql:MatchingOpQLParser,applypipeline:ApplyTermPipeline,context_wmodel:org.terrier.python.WmodelFromContextProcess,localmatching:LocalManager$ApplyLocalMatching,qe:QueryExpansion,labels:org.terrier.learning.LabelDecorator,filters:LocalManager$PostFilterProcess,decorate:SimpleDecorateProcess', 'querying.postfilters': 'decorate:SimpleDecorate,site:SiteFilter,scope:Scope', 'querying.default.controls': 'wmodel:DPH,parsecontrols:on,parseql:on,applypipeline:on,terrierql:on,localmatching:on,filters:on,decorate:on', 'querying.allowed.controls': 'scope,qe,qemodel,start,end,site,scope,applypipeline', 'termpipelines': 'Stopwords,PorterStemmer'}), <pyterrier.rewrite.Bo1QueryExpansion object at 0x7f690e056f50>), BR(/content/terrier_trec_covid_positional_indices/data.properties,{'terrierql': 'on', 'parsecontrols': 'on', 'parseql': 'on', 'applypipeline': 'on', 'localmatching': 'on', 'filters': 'on', 'decorate': 'on', 'wmodel': 'BM25'},{'querying.processes': 'terrierql:TerrierQLParser,parsecontrols:TerrierQLToControls,parseql:TerrierQLToMatchingQueryTerms,matchopql:MatchingOpQLParser,applypipeline:ApplyTermPipeline,context_wmodel:org.terrier.python.WmodelFromContextProcess,localmatching:LocalManager$ApplyLocalMatching,qe:QueryExpansion,labels:org.terrier.learning.LabelDecorator,filters:LocalManager$PostFilterProcess,decorate:SimpleDecorateProcess', 'querying.postfilters': 'decorate:SimpleDecorate,site:SiteFilter,scope:Scope', 'querying.default.controls': 'wmodel:DPH,parsecontrols:on,parseql:on,applypipeline:on,terrierql:on,localmatching:on,filters:on,decorate:on', 'querying.allowed.controls': 'scope,qe,qemodel,start,end,site,scope,applypipeline', 'termpipelines': 'Stopwords,PorterStemmer'})), expected 150 received 15000, feature scores for any missing documents be 0, extraneous documents will be removed\n",
            "  warn(\"Got number of results different expected from %s, expected %d received %d, feature scores for any missing documents be 0, extraneous documents will be removed\" % (repr(m), num_results, len(res)))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>map</th>\n",
              "      <th>ndcg</th>\n",
              "      <th>ndcg_cut_10</th>\n",
              "      <th>mrt</th>\n",
              "      <th>map +</th>\n",
              "      <th>map -</th>\n",
              "      <th>map p-value</th>\n",
              "      <th>ndcg +</th>\n",
              "      <th>ndcg -</th>\n",
              "      <th>ndcg p-value</th>\n",
              "      <th>ndcg_cut_10 +</th>\n",
              "      <th>ndcg_cut_10 -</th>\n",
              "      <th>ndcg_cut_10 p-value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BM25</td>\n",
              "      <td>0.010480</td>\n",
              "      <td>0.043844</td>\n",
              "      <td>0.537236</td>\n",
              "      <td>44.132469</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BM25+CA</td>\n",
              "      <td>0.012251</td>\n",
              "      <td>0.049097</td>\n",
              "      <td>0.578831</td>\n",
              "      <td>133.881183</td>\n",
              "      <td>9.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.035093</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.069393</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.128795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BM25+RF</td>\n",
              "      <td>0.011271</td>\n",
              "      <td>0.045830</td>\n",
              "      <td>0.551404</td>\n",
              "      <td>155.636978</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.216817</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.233364</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.420787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BM25+LMart</td>\n",
              "      <td>0.009926</td>\n",
              "      <td>0.042458</td>\n",
              "      <td>0.528034</td>\n",
              "      <td>146.815546</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.322366</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.503059</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.604548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>New BM25+CA</td>\n",
              "      <td>0.012226</td>\n",
              "      <td>0.049228</td>\n",
              "      <td>0.584731</td>\n",
              "      <td>231.222722</td>\n",
              "      <td>9.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.033117</td>\n",
              "      <td>9.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.057557</td>\n",
              "      <td>9.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.048612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>New BM25+RF</td>\n",
              "      <td>0.011132</td>\n",
              "      <td>0.047147</td>\n",
              "      <td>0.563326</td>\n",
              "      <td>260.207897</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.211093</td>\n",
              "      <td>8.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.129158</td>\n",
              "      <td>8.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.124830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>New BM25+LMart</td>\n",
              "      <td>0.009926</td>\n",
              "      <td>0.042458</td>\n",
              "      <td>0.528034</td>\n",
              "      <td>216.885468</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.322366</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.503059</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.604548</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             name       map  ...  ndcg_cut_10 -  ndcg_cut_10 p-value\n",
              "0            BM25  0.010480  ...            NaN                  NaN\n",
              "1         BM25+CA  0.012251  ...            4.0             0.128795\n",
              "2         BM25+RF  0.011271  ...            4.0             0.420787\n",
              "3      BM25+LMart  0.009926  ...            7.0             0.604548\n",
              "4     New BM25+CA  0.012226  ...            5.0             0.048612\n",
              "5     New BM25+RF  0.011132  ...            5.0             0.124830\n",
              "6  New BM25+LMart  0.009926  ...            7.0             0.604548\n",
              "\n",
              "[7 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}